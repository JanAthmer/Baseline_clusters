{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b3374e-ecbc-4961-8f01-cb9e5f60253e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/gpfs/home3/scur0635/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/gpfs/home3/scur0635/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "Collecting fastparquet\n",
      "  Using cached fastparquet-2023.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "Requirement already satisfied: fsspec in /gpfs/home3/scur0635/.local/lib/python3.9/site-packages (from fastparquet) (2023.10.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /gpfs/home3/scur0635/.local/lib/python3.9/site-packages (from fastparquet) (2.1.3)\n",
      "Requirement already satisfied: packaging in /gpfs/admin/_hpc/sw/arch/INTEL-AVX512/Centos8/EB_production/2021/software/Python/3.9.5-GCCcore-10.3.0/lib/python3.9/site-packages (from fastparquet) (20.9)\n",
      "Collecting cramjam>=2.3\n",
      "  Using cached cramjam-2.7.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /gpfs/home3/scur0635/.local/lib/python3.9/site-packages (from fastparquet) (1.26.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /gpfs/admin/_hpc/sw/arch/INTEL-AVX512/Centos8/EB_production/2021/software/Python/3.9.5-GCCcore-10.3.0/lib/python3.9/site-packages (from pandas>=1.5.0->fastparquet) (2021.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /gpfs/home3/scur0635/.local/lib/python3.9/site-packages (from pandas>=1.5.0->fastparquet) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /gpfs/home3/scur0635/.local/lib/python3.9/site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /gpfs/admin/_hpc/sw/arch/INTEL-AVX512/Centos8/EB_production/2021/software/Python/3.9.5-GCCcore-10.3.0/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /gpfs/admin/_hpc/sw/arch/INTEL-AVX512/Centos8/EB_production/2021/software/Python/3.9.5-GCCcore-10.3.0/lib/python3.9/site-packages (from packaging->fastparquet) (2.4.7)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/gpfs/home3/scur0635/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "Installing collected packages: cramjam, fastparquet\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/gpfs/home3/scur0635/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/gpfs/home3/scur0635/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "Successfully installed cramjam-2.7.0 fastparquet-2023.10.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/gpfs/home3/scur0635/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/gpfs/home3/scur0635/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/gpfs/home3/scur0635/.local/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/sw/arch/Centos8/EB_production/2021/software/Python/3.9.5-GCCcore-10.3.0/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet\n",
    "import spacy \n",
    "import spacy_transformers\n",
    "import hashlib\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d35ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy.cli.download('en_core_web_trf')\n",
    "# nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3046749b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['sentence_column', 'pos_tag_column']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/scur0635.4596111/ipykernel_2726559/3253823194.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.parquet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fastparquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence_column'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos_tag_column'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Assuming your sentence column is in column 0 and POS tag column is in column 4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdropna\u001b[0;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6416\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6417\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6418\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6419\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ['sentence_column', 'pos_tag_column']"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('train.parquet', engine='fastparquet')\n",
    "df = df.dropna(subset=['sentence_column', 'pos_tag_column'])\n",
    "\n",
    "# Assuming your sentence column is in column 0 and POS tag column is in column 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f1472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_column = df.iloc[:, 0]\n",
    "pos_tag_column = df.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4d9b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a defaultdict to store words, their corresponding POS tags, and their frequency\n",
    "vocabulary = defaultdict(lambda: {'pos_tags': set(), 'frequency': 0})\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for sentence, pos_tags in zip(sentence_column, pos_tag_column):\n",
    "    # Tokenize the sentence into words\n",
    "    words = sentence.split()\n",
    "    \n",
    "    # Make sure pos_tags is a list\n",
    "    if isinstance(pos_tags, list):\n",
    "        # Iterate over words and their corresponding POS tags\n",
    "        for word, pos_tag in zip(words, pos_tags):\n",
    "            # Update the vocabulary\n",
    "            vocabulary[word]['pos_tags'].add(pos_tag)\n",
    "            vocabulary[word]['frequency'] += 1\n",
    "\n",
    "# Convert the defaultdict to a regular dictionary\n",
    "vocabulary = dict(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a53741b8-3915-4c58-bea7-e536af19c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = 'wikitext-103.tar.gz'\n",
    "# url = 'https://dax-cdn.cdn.appdomain.cloud/dax-wikitext-103/1.0.1/' + fname\n",
    "# r = requests.get(url)\n",
    "# Path(fname).write_bytes(r.content)\n",
    "# with tarfile.open(fname) as tar:\n",
    "#     tar.extractall()\n",
    "# train_data = Path('wikitext-103/wiki.train.tokens').read_text(encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "438035d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4076530\n"
     ]
    }
   ],
   "source": [
    "print(len(sentence_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1a6a533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pos_tags': {'``', 'JJR', 'NNS', 'VBZ', 'WDT', 'CC', 'GW', 'TO', 'VBG', 'VBP', 'DT', 'VBD', '-LRB-', 'PRP$', 'RP', '-RRB-', 'JJS', 'RB', 'SYM', 'VBN', ':', \"''\", 'NN', 'VB', 'WRB', 'JJ', ',', 'IN', 'NNP'}, 'frequency': 508}\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary[\"friction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc34b82-c4f0-4912-b116-17dd72e62f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tagged = pos_tag(word_tokenize(train_data.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf3aad7b-f333-493b-adda-bc9b8f5fd159",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocab_file_tagged.json', 'w') as file:\n",
    "    json.dump(word_tagged, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a88fa6bc-de54-49f0-a75f-e235e4743042",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency_counter = Counter(word_tagged)\n",
    "sorted_words = sorted(word_frequency_counter.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7de2375d-d035-4100-86b1-f5a5afc6789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574607\n"
     ]
    }
   ],
   "source": [
    "with open('sorted_vocab_tagged.json', 'w') as file:\n",
    "    json.dump(sorted_words, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
