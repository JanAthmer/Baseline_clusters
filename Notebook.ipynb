{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZMuYmPleIbr"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6u2a6GKR_o2",
    "outputId": "a4698008-45db-4575-f8c1-1db68c8c8283"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#@title #**Setup:** Imports and dependencies\n",
    "#@markdown Install and import Python dependencies.\n",
    "location = 'vsc' #@param['colab', 'vsc']\n",
    "\n",
    "package = 'inseq' #@param['inseq', 'kayo', 'both']\n",
    "\n",
    "!pip install jsonlines\n",
    "import jsonlines\n",
    "import json\n",
    "\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import copy\n",
    "import sys\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import gc\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "if package == 'inseq' or package == 'both':\n",
    "  print('Installing dependencies inseq')\n",
    "  !pip install inseq\n",
    "  import inseq\n",
    "\n",
    "\n",
    "if package == 'kayo' or package == 'both':\n",
    "  print('Installing dependencies kayo')\n",
    "  !pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "  !git clone https://github.com/JanAthmer/Baseline_clusters.git &> /dev/null\n",
    "#   !git clone https://github.com/kayoyin/interpret-lm.git &> /dev/null\n",
    "  sys.path.append('./Baseline_clusters')\n",
    "#   sys.path.append('./interpret-lm')\n",
    "\n",
    "  from lm_saliency import *\n",
    "\n",
    "clear_output()\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JkZAqsOKhCsT",
    "outputId": "c6b95b96-8733-445d-c7e6-d2901c19c613"
   },
   "outputs": [],
   "source": [
    "#@title #**Setup:** load Drive\n",
    "if location == 'colab':\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cellView": "form",
    "id": "CQa4aaAA27B1"
   },
   "outputs": [],
   "source": [
    "#@title #**Utils:** reciprocal_rank, average\n",
    "\n",
    "def average(lst):\n",
    "  return sum(lst)/len(lst)\n",
    "\n",
    "\n",
    "def reciprocal_rank(predictions, targets):\n",
    "    # Combine predictions and targets into pairs\n",
    "    pairs = list(zip(predictions, targets))\n",
    "\n",
    "    # Sort the pairs based on the prediction values (in descending order)\n",
    "    sorted_pairs = sorted(pairs, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Find the rank of the first correct prediction\n",
    "    rank = next((i + 1 for i, (pred, target) in enumerate(sorted_pairs) if target), 0)\n",
    "\n",
    "    # Calculate reciprocal rank\n",
    "    reciprocal_rank = 1 / rank if rank > 0 else 0\n",
    "\n",
    "    return reciprocal_rank\n",
    "\n",
    "def get_target(sentence):\n",
    "    b = sentence.split(' ')\n",
    "    prefix_l = 0\n",
    "    postix_l = 0\n",
    "    target_l = 0\n",
    "    check = False\n",
    "    for i,word in enumerate(b):\n",
    "        if i != 0:\n",
    "            word = \" \"+word\n",
    "\n",
    "        if check == True:\n",
    "            postix_l += len(tokenizer(word)['input_ids'])\n",
    "        if \"n't\" in word:\n",
    "            target_l = len(tokenizer(word)['input_ids'])\n",
    "            check = True\n",
    "        if check == False:\n",
    "            prefix_l += len(tokenizer(word)['input_ids'])\n",
    "    return([False]*prefix_l+[True]*target_l+[False]*postix_l)\n",
    "\n",
    "import random\n",
    "\n",
    "def generate_one_hot_list(length):\n",
    "    # Check if the length is valid\n",
    "    if length <= 0:\n",
    "        raise ValueError(\"Length must be greater than 0\")\n",
    "\n",
    "    # Choose a random index for the \"hot\" element\n",
    "    hot_index = random.randint(0, length - 1)\n",
    "\n",
    "    # Create the one-hot list\n",
    "    one_hot_list = [0] * length\n",
    "    one_hot_list[hot_index] = 1\n",
    "\n",
    "    return one_hot_list\n",
    "\n",
    "def get_last_true_index(one_hot_vector):\n",
    "    \"\"\"\n",
    "    Get the index of the last True value in the one-hot vector.\n",
    "\n",
    "    Parameters:\n",
    "    one_hot_vector (list of bool): One-hot vector with possibly multiple True values.\n",
    "\n",
    "    Returns:\n",
    "    int: The index of the last True value in the one-hot vector, or -1 if no True values are found.\n",
    "    \"\"\"\n",
    "    last_true_index = -1\n",
    "    for i, value in enumerate(one_hot_vector):\n",
    "        if value:\n",
    "            last_true_index = i\n",
    "    return last_true_index\n",
    "\n",
    "def normalize_vector(vector):\n",
    "    \"\"\"\n",
    "    Normalize a vector between -1 and 1 by dividing each element by the absolute maximum value.\n",
    "\n",
    "    Args:\n",
    "    vector (numpy array): The input vector to be normalized.\n",
    "\n",
    "    Returns:\n",
    "    numpy array: The normalized vector.\n",
    "    \"\"\"\n",
    "    abs_max = max(abs(np.max(vector)), abs(np.min(vector)))\n",
    "    normalized_vector = vector / abs_max\n",
    "    return normalized_vector\n",
    "\n",
    "\n",
    "def normalize_and_truncate(vector_a, vector_b):\n",
    "    \"\"\"\n",
    "    Normalize two input vectors between -1 and 1 and truncate the longer vector to match the length of the shorter one.\n",
    "\n",
    "    Args:\n",
    "    vector_a (numpy array): The first input vector to be normalized and truncated.\n",
    "    vector_b (numpy array): The second input vector to be normalized and truncated.\n",
    "\n",
    "    Returns:\n",
    "    numpy array, numpy array: The normalized and truncated vectors A and B.\n",
    "    \"\"\"\n",
    "    # Normalize vector A\n",
    "    abs_max_a = max(abs(np.max(vector_a)), abs(np.min(vector_a)))\n",
    "    normalized_vector_a = vector_a / abs_max_a\n",
    "\n",
    "    # Normalize vector B\n",
    "    abs_max_b = max(abs(np.max(vector_b)), abs(np.min(vector_b)))\n",
    "    normalized_vector_b = vector_b / abs_max_b\n",
    "\n",
    "    # Determine which vector is longer and truncate it\n",
    "    if len(normalized_vector_a) > len(normalized_vector_b):\n",
    "        truncated_vector_a = normalized_vector_a[:len(normalized_vector_b)]\n",
    "        truncated_vector_b = normalized_vector_b\n",
    "    else:\n",
    "        truncated_vector_a = normalized_vector_a\n",
    "        truncated_vector_b = normalized_vector_b[:len(normalized_vector_a)]\n",
    "\n",
    "    return truncated_vector_a, truncated_vector_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bv3rgH4LeNW2"
   },
   "source": [
    "# Table run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We don't want to raise 3.671572208404541\n"
     ]
    }
   ],
   "source": [
    "with jsonlines.open(\"npi_present_1.jsonl\", 'r') as f:\n",
    "  dataframe_npi = pd.DataFrame(f)\n",
    "\n",
    "with jsonlines.open(\"determiner_noun_agreement_1.jsonl\", 'r') as f:\n",
    "  dataframe_dna = pd.DataFrame(f)\n",
    "\n",
    "sentences = []\n",
    "values = []\n",
    "with open(\"prefix+value.tsv\", 'r', encoding='utf-8') as ifh:\n",
    "  for line in ifh:\n",
    "      sentence, value = line.strip().split('\\t')\n",
    "      sentences.append(sentence)\n",
    "      values.append(value)\n",
    "print(sentence,value)\n",
    "\n",
    "with open(\"vocab_tagged.json\", 'r') as file:\n",
    "    vocabulary = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title #**Loop through 'ANY' NPI and give MRR**\n",
    "import torch\n",
    "explanation = \"occlusion\" #\"input_x_gradient\", \"integrated_gradients\", \"lime\", \"deeplift\", \"gradient_shap\",\"discretized_integrated_gradients\"\n",
    "attributed_fns = [\"logit\",\"probability\"] #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "revs = [\"False\",\"True\"]\n",
    "NORM = False\n",
    "data = \"any\"\n",
    "# normalize = [\"True\", \"False\"]\n",
    "\n",
    "model_inseq = inseq.load_model(\"gpt2\", explanation)\n",
    "\n",
    "base_l = []\n",
    "base_p = []\n",
    "\n",
    "contrast_l_T = []\n",
    "contrast_l_F = []\n",
    "contrast_p_T = []\n",
    "contrast_p_F = []\n",
    "\n",
    "contrast_rnd_l_T = []\n",
    "contrast_rnd_l_F = []\n",
    "contrast_rnd_p_T = []\n",
    "contrast_rnd_p_F = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "for attributed_fn in attributed_fns:\n",
    "    \n",
    "    base = False\n",
    "    \n",
    "    if attributed_fn == 'logit':\n",
    "        contrast_attributed_fn = \"contrast_logits_diff\"\n",
    "    if attributed_fn == 'probability':\n",
    "        contrast_attributed_fn = \"contrast_prob_diff\"\n",
    "        \n",
    "    for rev in revs:\n",
    "        for sentence in sentences:\n",
    "            i += 1\n",
    "            print(i)\n",
    "            target = \"any\"\n",
    "#             foil = \"some\"\n",
    "            foil_rnd = random.sample(vocabulary,1)[0][0][0]\n",
    "#         for index, row in dataframe_npi.iterrows():\n",
    "#             print(index)\n",
    "#             sentence = row[\"one_prefix_prefix\"]\n",
    "#             target = row[\"one_prefix_word_good\"]\n",
    "# #             foil = row[\"one_prefix_word_bad\"]\n",
    "#             foil_rnd = random.sample(vocabulary,1)[0][0][0]\n",
    "                \n",
    "            if rev == 'False':\n",
    "\n",
    "                contrast_rnd = model_inseq.attribute(\n",
    "                  sentence,\n",
    "                  sentence + \" \" + target,\n",
    "                  attributed_fn= contrast_attributed_fn,\n",
    "                  contrast_targets= sentence + \" \" + foil_rnd,\n",
    "                  step_scores=[contrast_attributed_fn]\n",
    "                )\n",
    "                \n",
    "            if rev == 'True':\n",
    "                \n",
    "                contrast_rnd = model_inseq.attribute(\n",
    "                  sentence,\n",
    "                  sentence + \" \" + foil_rnd,\n",
    "                  attributed_fn= contrast_attributed_fn,\n",
    "                  contrast_targets= sentence + \" \" + target,\n",
    "                  step_scores=[contrast_attributed_fn]\n",
    "                )         \n",
    "\n",
    "            clear_output()\n",
    "            \n",
    "            contrastive_rnd_tensor = contrast_rnd[0].target_attributions\n",
    "            contrast_rnd_att = contrastive_rnd_tensor\n",
    "\n",
    "            contrast_rnd_att = torch.flatten(contrast_rnd_att[~torch.any(contrast_rnd_att.isnan(),dim=1)]).numpy()\n",
    "                \n",
    "                \n",
    "            if data == \"any\":\n",
    "                targets = get_target(sentence)\n",
    "            elif data == \"npi\":\n",
    "                sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "                targets = [True] + [False] * (sent_len - 1)\n",
    "            elif data == \"dna\":\n",
    "                sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "                targets = [False] * (sent_len - 1)+[True]\n",
    "\n",
    "            contrast_rnd_mmr = reciprocal_rank(contrast_rnd_att, targets)\n",
    "            \n",
    "            if rev == 'True':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_rnd_l_T.append(contrast_rnd_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':\n",
    "                    contrast_rnd_p_T.append(contrast_rnd_mmr)\n",
    "                    \n",
    "            elif rev == 'False':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_rnd_l_F.append(contrast_rnd_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':         \n",
    "                    contrast_rnd_p_F.append(contrast_rnd_mmr)\n",
    "\n",
    "\n",
    "# results = {'base_l':base_l,'base_p':base_p,'contrast_l_T':contrast_l_T,'contrast_l_F':contrast_l_F,'contrast_p_T':contrast_p_T,\n",
    "#            'contrast_p_F':contrast_p_F,'contrast_rnd_l_T':contrast_rnd_l_T,'contrast_rnd_l_F':contrast_rnd_l_F,'contrast_rnd_p_T':contrast_rnd_p_T\n",
    "#            ,'contrast_rnd_p_F':contrast_rnd_p_F}\n",
    "\n",
    "results = {'contrast_rnd_l_T':contrast_rnd_l_T,'contrast_rnd_l_F':contrast_rnd_l_F,'contrast_rnd_p_T':contrast_rnd_p_T\n",
    "           ,'contrast_rnd_p_F':contrast_rnd_p_F}\n",
    "\n",
    "dataframe_results_inputx = pd.DataFrame(data=results)\n",
    "dataframe_results_inputx.to_csv(f'occlusion_sample_all_{data}.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title #**Loop through 'ANY' NPI and give MRR**\n",
    "import torch\n",
    "explanation = \"occlusion\" #\"input_x_gradient\", \"integrated_gradients\", \"lime\", \"deeplift\", \"gradient_shap\",\"discretized_integrated_gradients\"\n",
    "attributed_fns = [\"logit\",\"probability\"] #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "revs = [\"False\",\"True\"]\n",
    "NORM = False\n",
    "data = \"npi\"\n",
    "# normalize = [\"True\", \"False\"]\n",
    "\n",
    "model_inseq = inseq.load_model(\"gpt2\", explanation)\n",
    "\n",
    "base_l = []\n",
    "base_p = []\n",
    "\n",
    "contrast_l_T = []\n",
    "contrast_l_F = []\n",
    "contrast_p_T = []\n",
    "contrast_p_F = []\n",
    "\n",
    "contrast_rnd_l_T = []\n",
    "contrast_rnd_l_F = []\n",
    "contrast_rnd_p_T = []\n",
    "contrast_rnd_p_F = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "for attributed_fn in attributed_fns:\n",
    "    \n",
    "    base = False\n",
    "    \n",
    "    if attributed_fn == 'logit':\n",
    "        contrast_attributed_fn = \"contrast_logits_diff\"\n",
    "    if attributed_fn == 'probability':\n",
    "        contrast_attributed_fn = \"contrast_prob_diff\"\n",
    "        \n",
    "    for rev in revs:\n",
    "        for index, row in dataframe_npi.iterrows():\n",
    "            print(index)\n",
    "            sentence = row[\"one_prefix_prefix\"]\n",
    "            target = row[\"one_prefix_word_good\"]\n",
    "#             foil = row[\"one_prefix_word_bad\"]\n",
    "            foil_rnd = random.sample(vocabulary,1)[0][0][0]\n",
    "                \n",
    "            if rev == 'False':\n",
    "\n",
    "                contrast_rnd = model_inseq.attribute(\n",
    "                  sentence,\n",
    "                  sentence + \" \" + target,\n",
    "                  attributed_fn= contrast_attributed_fn,\n",
    "                  contrast_targets= sentence + \" \" + foil_rnd,\n",
    "                  step_scores=[contrast_attributed_fn]\n",
    "                )\n",
    "                \n",
    "            if rev == 'True':\n",
    "                \n",
    "                contrast_rnd = model_inseq.attribute(\n",
    "                  sentence,\n",
    "                  sentence + \" \" + foil_rnd,\n",
    "                  attributed_fn= contrast_attributed_fn,\n",
    "                  contrast_targets= sentence + \" \" + target,\n",
    "                  step_scores=[contrast_attributed_fn]\n",
    "                )         \n",
    "\n",
    "            clear_output()\n",
    "\n",
    "            contrastive_rnd_tensor = contrast_rnd[0].target_attributions\n",
    "            contrast_rnd_att = contrastive_rnd_tensor\n",
    "            contrast_rnd_att = torch.flatten(contrast_rnd_att[~torch.any(contrast_rnd_att.isnan(),dim=1)]).numpy()\n",
    "\n",
    "                \n",
    "                \n",
    "            if data == \"any\":\n",
    "                targets = get_target(sentence)\n",
    "            elif data == \"npi\":\n",
    "                sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "                targets = [True] + [False] * (sent_len - 1)\n",
    "            elif data == \"dna\":\n",
    "                sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "                targets = [False] * (sent_len - 1)+[True]\n",
    "\n",
    "            contrast_rnd_mmr = reciprocal_rank(contrast_rnd_att, targets)\n",
    "            \n",
    "            if rev == 'True':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_rnd_l_T.append(contrast_rnd_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':\n",
    "                    contrast_rnd_p_T.append(contrast_rnd_mmr)\n",
    "                    \n",
    "            elif rev == 'False':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_rnd_l_F.append(contrast_rnd_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':         \n",
    "                    contrast_rnd_p_F.append(contrast_rnd_mmr)\n",
    "\n",
    "\n",
    "# results = {'base_l':base_l,'base_p':base_p,'contrast_l_T':contrast_l_T,'contrast_l_F':contrast_l_F,'contrast_p_T':contrast_p_T,\n",
    "#            'contrast_p_F':contrast_p_F,'contrast_rnd_l_T':contrast_rnd_l_T,'contrast_rnd_l_F':contrast_rnd_l_F,'contrast_rnd_p_T':contrast_rnd_p_T\n",
    "#            ,'contrast_rnd_p_F':contrast_rnd_p_F}\n",
    "\n",
    "results = {'contrast_rnd_l_T':contrast_rnd_l_T,'contrast_rnd_l_F':contrast_rnd_l_F,'contrast_rnd_p_T':contrast_rnd_p_T\n",
    "           ,'contrast_rnd_p_F':contrast_rnd_p_F}\n",
    "\n",
    "dataframe_results_inputx = pd.DataFrame(data=results)\n",
    "dataframe_results_inputx.to_csv(f'occlusion_sample_all_{data}.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title #**Loop through 'ANY' NPI and give MRR**\n",
    "import torch\n",
    "explanation = \"occlusion\" #\"input_x_gradient\", \"integrated_gradients\", \"lime\", \"deeplift\", \"gradient_shap\",\"discretized_integrated_gradients\"\n",
    "attributed_fns = [\"logit\",\"probability\"] #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "revs = [\"False\",\"True\"]\n",
    "NORM = False\n",
    "data = \"dna\"\n",
    "# normalize = [\"True\", \"False\"]\n",
    "\n",
    "model_inseq = inseq.load_model(\"gpt2\", explanation)\n",
    "\n",
    "base_l = []\n",
    "base_p = []\n",
    "\n",
    "contrast_l_T = []\n",
    "contrast_l_F = []\n",
    "contrast_p_T = []\n",
    "contrast_p_F = []\n",
    "\n",
    "contrast_rnd_l_T = []\n",
    "contrast_rnd_l_F = []\n",
    "contrast_rnd_p_T = []\n",
    "contrast_rnd_p_F = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "for attributed_fn in attributed_fns:\n",
    "    \n",
    "    base = False\n",
    "    \n",
    "    if attributed_fn == 'logit':\n",
    "        contrast_attributed_fn = \"contrast_logits_diff\"\n",
    "    if attributed_fn == 'probability':\n",
    "        contrast_attributed_fn = \"contrast_prob_diff\"\n",
    "        \n",
    "    for rev in revs:\n",
    "        for index, row in dataframe_dna.iterrows():\n",
    "            print(index)\n",
    "            sentence = row[\"one_prefix_prefix\"]\n",
    "            target = row[\"one_prefix_word_good\"]\n",
    "#             foil = row[\"one_prefix_word_bad\"]\n",
    "            foil_rnd = random.sample(vocabulary,1)[0][0][0]\n",
    "                \n",
    "            if rev == 'False':\n",
    "\n",
    "                contrast_rnd = model_inseq.attribute(\n",
    "                  sentence,\n",
    "                  sentence + \" \" + target,\n",
    "                  attributed_fn= contrast_attributed_fn,\n",
    "                  contrast_targets= sentence + \" \" + foil_rnd,\n",
    "                  step_scores=[contrast_attributed_fn]\n",
    "                )\n",
    "                \n",
    "            if rev == 'True':\n",
    "                \n",
    "                contrast_rnd = model_inseq.attribute(\n",
    "                  sentence,\n",
    "                  sentence + \" \" + foil_rnd,\n",
    "                  attributed_fn= contrast_attributed_fn,\n",
    "                  contrast_targets= sentence + \" \" + target,\n",
    "                  step_scores=[contrast_attributed_fn]\n",
    "                )         \n",
    "\n",
    "            clear_output()\n",
    "\n",
    "            contrastive_rnd_tensor = contrast_rnd[0].target_attributions\n",
    "            contrast_rnd_att = contrastive_rnd_tensor\n",
    "            contrast_rnd_att = torch.flatten(contrast_rnd_att[~torch.any(contrast_rnd_att.isnan(),dim=1)]).numpy()\n",
    "                \n",
    "                \n",
    "            if data == \"any\":\n",
    "                targets = get_target(sentence)\n",
    "            elif data == \"npi\":\n",
    "                sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "                targets = [True] + [False] * (sent_len - 1)\n",
    "            elif data == \"dna\":\n",
    "                sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "                targets = [False] * (sent_len - 1)+[True]\n",
    "\n",
    "            contrast_rnd_mmr = reciprocal_rank(contrast_rnd_att, targets)\n",
    "            \n",
    "            if rev == 'True':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_rnd_l_T.append(contrast_rnd_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':\n",
    "                    contrast_rnd_p_T.append(contrast_rnd_mmr)\n",
    "                    \n",
    "            elif rev == 'False':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_rnd_l_F.append(contrast_rnd_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':         \n",
    "                    contrast_rnd_p_F.append(contrast_rnd_mmr)\n",
    "\n",
    "\n",
    "# results = {'base_l':base_l,'base_p':base_p,'contrast_l_T':contrast_l_T,'contrast_l_F':contrast_l_F,'contrast_p_T':contrast_p_T,\n",
    "#            'contrast_p_F':contrast_p_F,'contrast_rnd_l_T':contrast_rnd_l_T,'contrast_rnd_l_F':contrast_rnd_l_F,'contrast_rnd_p_T':contrast_rnd_p_T\n",
    "#            ,'contrast_rnd_p_F':contrast_rnd_p_F}\n",
    "\n",
    "results = {'contrast_rnd_l_T':contrast_rnd_l_T,'contrast_rnd_l_F':contrast_rnd_l_F,'contrast_rnd_p_T':contrast_rnd_p_T\n",
    "           ,'contrast_rnd_p_F':contrast_rnd_p_F}\n",
    "\n",
    "dataframe_results_inputx = pd.DataFrame(data=results)\n",
    "dataframe_results_inputx.to_csv(f'occlusion_sample_all_{data}.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title #**Loop through 'ANY' NPI and give MRR**\n",
    "\n",
    "import torch\n",
    "explanation = \"input_x_gradient\" #\"input_x_gradient\", \"integrated_gradients\", \"lime\", \"deeplift\", \"gradient_shap\",\"discretized_integrated_gradients\"\n",
    "attributed_fns = [\"logit\",\"probability\"] #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "revs = [\"False\",\"True\"]\n",
    "NORM = True\n",
    "data = \"dna\"\n",
    "\n",
    "model_inseq = inseq.load_model(\"gpt2\", explanation)\n",
    "\n",
    "base_l = []\n",
    "base_p = []\n",
    "\n",
    "contrast_l_T = []\n",
    "contrast_l_F = []\n",
    "contrast_p_T = []\n",
    "contrast_p_F = []\n",
    "\n",
    "contrast_rnd_l_T = []\n",
    "contrast_rnd_l_F = []\n",
    "contrast_rnd_p_T = []\n",
    "contrast_rnd_p_F = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "for attributed_fn in attributed_fns:\n",
    "    \n",
    "    base = False\n",
    "    \n",
    "    if attributed_fn == 'logit':\n",
    "        contrast_attributed_fn = \"contrast_logits_diff\"\n",
    "    if attributed_fn == 'probability':\n",
    "        contrast_attributed_fn = \"contrast_prob_diff\"\n",
    "        \n",
    "    for rev in revs:\n",
    "#         for sentence in sentences:\n",
    "#             i += 1\n",
    "#             print(i)\n",
    "#             target = \"any\"\n",
    "#             foil_rnd = random.sample(vocabulary,1)[0][0][0]\n",
    "        for index, row in dataframe_dna.iterrows():\n",
    "            print(index)\n",
    "            sentence = row[\"one_prefix_prefix\"]\n",
    "            target = row[\"one_prefix_word_good\"]\n",
    "            foil_rnd = random.sample(vocabulary,1)[0][0][0]\n",
    "\n",
    "            baseline = model_inseq.attribute(\n",
    "                sentence,\n",
    "                sentence + \" \" + target,\n",
    "                attributed_fn=attributed_fn,\n",
    "            )\n",
    "                              \n",
    "            contrast_rnd = model_inseq.attribute(\n",
    "                sentence,\n",
    "                sentence + \" \" + foil_rnd,\n",
    "                attributed_fn=attributed_fn,\n",
    "            )                      \n",
    "\n",
    "            clear_output()\n",
    "\n",
    "            base_tensor = baseline[0].target_attributions\n",
    "            contrastive_rnd_tensor = contrast_rnd[0].target_attributions\n",
    "\n",
    "            baseline_att = base_tensor.sum(axis = 2)\n",
    "            contrast_rnd_att = contrastive_rnd_tensor.sum(axis = 2)\n",
    "\n",
    "            baseline_att = torch.flatten(baseline_att[~torch.any(baseline_att.isnan(),dim=1)]).numpy()\n",
    "            contrast_rnd_att = torch.flatten(contrast_rnd_att[~torch.any(contrast_rnd_att.isnan(),dim=1)]).numpy()\n",
    "\n",
    "            if NORM == True:\n",
    "                baseline_att, contrast_rnd_att = normalize_and_truncate(baseline_att, contrast_rnd_att)\n",
    "                if rev == 'True':\n",
    "                    contrast_rnd_att = contrast_rnd_att-baseline_att\n",
    "                elif rev == 'False':\n",
    "                    contrast_rnd_att = baseline_att - contrast_rnd_att               \n",
    "                \n",
    "            if data == \"any\":\n",
    "                targets = get_target(sentence)\n",
    "            elif data == \"npi\":\n",
    "                sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "                targets = [True] + [False] * (sent_len - 1)\n",
    "            elif data == \"dna\":\n",
    "                sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "                targets = [False] * (sent_len - 1)+[True]\n",
    "            \n",
    "            base_mmr = reciprocal_rank(baseline_att, targets)\n",
    "            contrast_rnd_mmr = reciprocal_rank(contrast_rnd_att, targets)\n",
    "            \n",
    "            if rev == 'True':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_rnd_l_T.append(contrast_rnd_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':\n",
    "                    contrast_rnd_p_T.append(contrast_rnd_mmr)\n",
    "                    \n",
    "            elif rev == 'False':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_rnd_l_F.append(contrast_rnd_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':         \n",
    "                    contrast_rnd_p_F.append(contrast_rnd_mmr)\n",
    "\n",
    "                            \n",
    "results = {'contrast_rnd_l_T':contrast_rnd_l_T,'contrast_rnd_l_F':contrast_rnd_l_F,'contrast_rnd_p_T':contrast_rnd_p_T\n",
    "           ,'contrast_rnd_p_F':contrast_rnd_p_F}\n",
    "\n",
    "dataframe_results_inputx = pd.DataFrame(data=results)\n",
    "dataframe_results_inputx.to_csv(f'X_norm_sample_all_{data}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "explanation = \"input_x_gradient\" #\"input_x_gradient\", \"integrated_gradients\", \"lime\", \"deeplift\", \"gradient_shap\",\"discretized_integrated_gradients\"\n",
    "attributed_fns = [\"logit\",\"probability\"] #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "revs = [\"False\",\"True\"]\n",
    "NORM = True\n",
    "data = \"npi\"\n",
    "\n",
    "model_inseq = inseq.load_model(\"gpt2\", explanation)\n",
    "\n",
    "base_l = []\n",
    "base_p = []\n",
    "\n",
    "contrast_l_T = []\n",
    "contrast_l_F = []\n",
    "contrast_p_T = []\n",
    "contrast_p_F = []\n",
    "\n",
    "contrast_rnd_l_T = []\n",
    "contrast_rnd_l_F = []\n",
    "contrast_rnd_p_T = []\n",
    "contrast_rnd_p_F = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "for attributed_fn in attributed_fns:\n",
    "    \n",
    "    base = False\n",
    "    \n",
    "    if attributed_fn == 'logit':\n",
    "        contrast_attributed_fn = \"contrast_logits_diff\"\n",
    "    if attributed_fn == 'probability':\n",
    "        contrast_attributed_fn = \"contrast_prob_diff\"\n",
    "        \n",
    "    for rev in revs:\n",
    "#         for sentence in sentences:\n",
    "#             i += 1\n",
    "#             print(i)\n",
    "#             target = \"any\"\n",
    "#             foil_rnd = random.sample(vocabulary,1)[0][0][0]\n",
    "        for index, row in dataframe_npi.iterrows():\n",
    "            print(index)\n",
    "            sentence = row[\"one_prefix_prefix\"]\n",
    "            target = row[\"one_prefix_word_good\"]\n",
    "            foil_rnd = random.sample(vocabulary,1)[0][0][0]\n",
    "\n",
    "            baseline = model_inseq.attribute(\n",
    "                sentence,\n",
    "                sentence + \" \" + target,\n",
    "                attributed_fn=attributed_fn,\n",
    "            )\n",
    "                              \n",
    "            contrast_rnd = model_inseq.attribute(\n",
    "                sentence,\n",
    "                sentence + \" \" + foil_rnd,\n",
    "                attributed_fn=attributed_fn,\n",
    "            )                      \n",
    "\n",
    "            clear_output()\n",
    "\n",
    "            base_tensor = baseline[0].target_attributions\n",
    "            contrastive_rnd_tensor = contrast_rnd[0].target_attributions\n",
    "\n",
    "            baseline_att = base_tensor.sum(axis = 2)\n",
    "            contrast_rnd_att = contrastive_rnd_tensor.sum(axis = 2)\n",
    "\n",
    "            baseline_att = torch.flatten(baseline_att[~torch.any(baseline_att.isnan(),dim=1)]).numpy()\n",
    "            contrast_rnd_att = torch.flatten(contrast_rnd_att[~torch.any(contrast_rnd_att.isnan(),dim=1)]).numpy()\n",
    "\n",
    "\n",
    "            if NORM == True:\n",
    "                baseline_att, contrast_rnd_att = normalize_and_truncate(baseline_att, contrast_rnd_att)\n",
    "                if rev == 'True':\n",
    "                    contrast_rnd_att = contrast_rnd_att-baseline_att\n",
    "                elif rev == 'False':\n",
    "                    contrast_rnd_att = baseline_att - contrast_rnd_att      \n",
    "                \n",
    "            if data == \"any\":\n",
    "                targets = get_target(sentence)\n",
    "            elif data == \"npi\":\n",
    "                sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "                targets = [True] + [False] * (sent_len - 1)\n",
    "            elif data == \"dna\":\n",
    "                sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "                targets = [False] * (sent_len - 1)+[True]\n",
    "            \n",
    "            base_mmr = reciprocal_rank(baseline_att, targets)\n",
    "            contrast_rnd_mmr = reciprocal_rank(contrast_rnd_att, targets)\n",
    "            \n",
    "            if rev == 'True':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_rnd_l_T.append(contrast_rnd_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':\n",
    "                    contrast_rnd_p_T.append(contrast_rnd_mmr)\n",
    "                    \n",
    "            elif rev == 'False':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_rnd_l_F.append(contrast_rnd_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':         \n",
    "                    contrast_rnd_p_F.append(contrast_rnd_mmr)\n",
    "\n",
    "                            \n",
    "results = {'contrast_rnd_l_T':contrast_rnd_l_T,'contrast_rnd_l_F':contrast_rnd_l_F,'contrast_rnd_p_T':contrast_rnd_p_T\n",
    "           ,'contrast_rnd_p_F':contrast_rnd_p_F}\n",
    "\n",
    "dataframe_results_inputx = pd.DataFrame(data=results)\n",
    "dataframe_results_inputx.to_csv(f'X_norm_sample_all_{data}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12056\n"
     ]
    }
   ],
   "source": [
    "# @title #**Loop through 'ANY' NPI and give MRR**\n",
    "import torch\n",
    "explanation = \"input_x_gradient\" #\"input_x_gradient\", \"integrated_gradients\", \"lime\", \"deeplift\", \"gradient_shap\",\"discretized_integrated_gradients\"\n",
    "attributed_fns = [\"logit\",\"probability\"] #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "revs = [\"False\",\"True\"]\n",
    "NORM = True\n",
    "data = \"any\"\n",
    "\n",
    "model_inseq = inseq.load_model(\"gpt2\", explanation)\n",
    "\n",
    "base_l = []\n",
    "base_p = []\n",
    "\n",
    "contrast_l_T = []\n",
    "contrast_l_F = []\n",
    "contrast_p_T = []\n",
    "contrast_p_F = []\n",
    "\n",
    "contrast_rnd_l_T = []\n",
    "contrast_rnd_l_F = []\n",
    "contrast_rnd_p_T = []\n",
    "contrast_rnd_p_F = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "for attributed_fn in attributed_fns:\n",
    "    \n",
    "    base = False\n",
    "    \n",
    "    if attributed_fn == 'logit':\n",
    "        contrast_attributed_fn = \"contrast_logits_diff\"\n",
    "    if attributed_fn == 'probability':\n",
    "        contrast_attributed_fn = \"contrast_prob_diff\"\n",
    "        \n",
    "    for rev in revs:\n",
    "        for sentence in sentences:\n",
    "            i += 1\n",
    "            print(i)\n",
    "            target = \"any\"\n",
    "            foil_rnd = random.sample(vocabulary,1)[0][0][0]\n",
    "\n",
    "\n",
    "            baseline = model_inseq.attribute(\n",
    "                sentence,\n",
    "                sentence + \" \" + target,\n",
    "                attributed_fn=attributed_fn,\n",
    "            )\n",
    "                              \n",
    "            contrast_rnd = model_inseq.attribute(\n",
    "                sentence,\n",
    "                sentence + \" \" + foil_rnd,\n",
    "                attributed_fn=attributed_fn,\n",
    "            )                      \n",
    "\n",
    "            clear_output()\n",
    "\n",
    "            base_tensor = baseline[0].target_attributions\n",
    "            contrastive_rnd_tensor = contrast_rnd[0].target_attributions\n",
    "\n",
    "            baseline_att = base_tensor.sum(axis = 2)\n",
    "            contrast_rnd_att = contrastive_rnd_tensor.sum(axis = 2)\n",
    "\n",
    "            baseline_att = torch.flatten(baseline_att[~torch.any(baseline_att.isnan(),dim=1)]).numpy()\n",
    "            contrast_rnd_att = torch.flatten(contrast_rnd_att[~torch.any(contrast_rnd_att.isnan(),dim=1)]).numpy()\n",
    "\n",
    "            if NORM == True:\n",
    "                baseline_att, contrast_rnd_att = normalize_and_truncate(baseline_att, contrast_rnd_att)\n",
    "                if rev == 'True':\n",
    "                    contrast_rnd_att = contrast_rnd_att-baseline_att\n",
    "                elif rev == 'False':\n",
    "                    contrast_rnd_att = baseline_att - contrast_rnd_att      \n",
    "                \n",
    "                \n",
    "            if data == \"any\":\n",
    "                targets = get_target(sentence)\n",
    "            elif data == \"npi\":\n",
    "                sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "                targets = [True] + [False] * (sent_len - 1)\n",
    "            elif data == \"dna\":\n",
    "                sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "                targets = [False] * (sent_len - 1)+[True]\n",
    "            \n",
    "            base_mmr = reciprocal_rank(baseline_att, targets)\n",
    "            contrast_rnd_mmr = reciprocal_rank(contrast_rnd_att, targets)\n",
    "            \n",
    "            if rev == 'True':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_rnd_l_T.append(contrast_rnd_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':\n",
    "                    contrast_rnd_p_T.append(contrast_rnd_mmr)\n",
    "                    \n",
    "            elif rev == 'False':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_rnd_l_F.append(contrast_rnd_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':         \n",
    "                    contrast_rnd_p_F.append(contrast_rnd_mmr)\n",
    "\n",
    "                            \n",
    "results = {'contrast_rnd_l_T':contrast_rnd_l_T,'contrast_rnd_l_F':contrast_rnd_l_F,'contrast_rnd_p_T':contrast_rnd_p_T\n",
    "           ,'contrast_rnd_p_F':contrast_rnd_p_F}\n",
    "\n",
    "dataframe_results_inputx = pd.DataFrame(data=results)\n",
    "dataframe_results_inputx.to_csv(f'X_norm_sample_all_{data}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Attributing with input_x_gradient...: 100%|██████████| 6/6 [00:00<00:00, 45.40it/s]\n",
      "\n",
      "\n",
      "Attributing with input_x_gradient...:  83%|████████▎ | 5/6 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/scur0635.5732649/ipykernel_742616/1581772779.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     99\u001b[0m             )\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             contrast_rnd = model_inseq.attribute(\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0msentence\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfoil_rnd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/inseq/models/attribution_model.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, input_texts, generated_texts, method, override_default_attribution, attr_pos_start, attr_pos_end, show_progress, pretty_progress, output_step_attributions, attribute_target, step_scores, include_eos_baseline, attributed_fn, device, batch_size, generate_from_target_prefix, generation_args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Batched attribution currently not supported for LIME. Using batch size of 1.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         attribution_outputs = attribution_method.prepare_and_attribute(\n\u001b[0m\u001b[1;32m    446\u001b[0m             \u001b[0minput_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mgenerated_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/inseq/attr/attribution_decorators.py\u001b[0m in \u001b[0;36mbatched_wrapper\u001b[0;34m(self, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mbatched_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/inseq/attr/feat/feature_attribution.py\u001b[0m in \u001b[0;36mprepare_and_attribute\u001b[0;34m(self, sources, targets, attr_pos_start, attr_pos_end, show_progress, pretty_progress, output_step_attributions, attribute_target, step_scores, include_eos_baseline, attributed_fn, attribution_args, attributed_fn_args, step_scores_args)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# of AttributionModel.attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mattributed_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribution_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attributed_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributed_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         attribution_output = self.attribute(\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mattributed_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattributed_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/inseq/attr/feat/feature_attribution.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, batch, attributed_fn, attr_pos_start, attr_pos_end, show_progress, pretty_progress, output_step_attributions, attribute_target, step_scores, attribution_args, attributed_fn_args, step_scores_args)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_pos_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_pos_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mtgt_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_step_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_attention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             step_output = self.filtered_attribute_step(\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0mtarget_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/inseq/attr/feat/feature_attribution.py\u001b[0m in \u001b[0;36mfiltered_attribute_step\u001b[0;34m(self, batch, target_ids, attributed_fn, target_attention_mask, attribute_target, step_scores, attribution_args, attributed_fn_args, step_scores_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m                 \u001b[0mattribution_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mattribution_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhidden_states_dict\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;31m# Perform attribution step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         step_output = self.attribute_step(\n\u001b[0m\u001b[1;32m    580\u001b[0m             \u001b[0mattribute_main_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0mattribution_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/inseq/attr/feat/gradient_attribution.py\u001b[0m in \u001b[0;36mattribute_step\u001b[0;34m(self, attribute_fn_main_args, attribution_args)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0minformation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mlater\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mfilled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0menrich_step_output\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mattribute_fn_main_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mattribution_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         if (\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/captum/attr/_core/input_x_gradient.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mgradient_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_gradient_requirements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         gradients = self.gradient_func(\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# runs forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         assert outputs[0].numel() == 1, (\n\u001b[1;32m    114\u001b[0m             \u001b[0;34m\"Target not provided when necessary, cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0madditional_forward_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_additional_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     output = forward_func(\n\u001b[0m\u001b[1;32m    483\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madditional_forward_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/inseq/models/decoder_only.py\u001b[0m in \u001b[0;36mformatted_forward_input_wrapper\u001b[0;34m(self, forward_tensor, input_ids, target_ids, attributed_fn, attention_mask, use_embeddings, attributed_fn_argnames, *args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mdecoder_input_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforward_tensor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_embeddings\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             )\n\u001b[0;32m--> 187\u001b[0;31m             return forward_fn(\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributed_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributed_fn_argnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/inseq/models/decoder_only.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_forward_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mLogitsTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_forward_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/inseq/models/attribution_model.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, batch, target_ids, attributed_fn, use_embeddings, attributed_fn_argnames, *args, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributed_fn_argnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Number of arguments and number of argnames must match\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0mtarget_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_forward_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"logits: {pretty_tensor(output.logits)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         step_fn_args = self.formatter.format_step_function_args(\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/inseq/models/decoder_only.py\u001b[0m in \u001b[0;36mget_forward_output\u001b[0;34m(self, batch, use_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     ) -> ModelOutput:\n\u001b[0;32m--> 216\u001b[0;31m         return self.model(\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_embeddings\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_embeds\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_embeddings\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1077\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    898\u001b[0m                 )\n\u001b[1;32m    899\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    901\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0msize_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#             if rev == 'False':\n",
    "#                 contrast = model_inseq.attribute(\n",
    "#                   sentence,\n",
    "#                   sentence + \" \" + target,\n",
    "#                   attributed_fn= contrast_attributed_fn,\n",
    "#                   contrast_targets= sentence + \" \" + foil,\n",
    "#                   step_scores=[contrast_attributed_fn]\n",
    "#                 )\n",
    "                \n",
    "#                 contrast_rnd = model_inseq.attribute(\n",
    "#                   sentence,\n",
    "#                   sentence + \" \" + target,\n",
    "#                   attributed_fn= contrast_attributed_fn,\n",
    "#                   contrast_targets= sentence + \" \" + foil_rnd,\n",
    "#                   step_scores=[contrast_attributed_fn]\n",
    "#                 )\n",
    "                \n",
    "#             if rev == 'True':\n",
    "#                 contrast = model_inseq.attribute(\n",
    "#                   sentence,\n",
    "#                   sentence + \" \" + foil,\n",
    "#                   attributed_fn= contrast_attributed_fn,\n",
    "#                   contrast_targets= sentence + \" \" + target,\n",
    "#                   step_scores=[contrast_attributed_fn]\n",
    "#                 )\n",
    "                \n",
    "#                 contrast_rnd = model_inseq.attribute(\n",
    "#                   sentence,\n",
    "#                   sentence + \" \" + foil_rnd,\n",
    "#                   attributed_fn= contrast_attributed_fn,\n",
    "#                   contrast_targets= sentence + \" \" + target,\n",
    "#                   step_scores=[contrast_attributed_fn]\n",
    "#                 )\n",
    "\n",
    "#@title #**Loop through 'ANY' NPI and give MRR**\n",
    "# import torch\n",
    "# explanation = \"input_x_gradient\" #\"input_x_gradient\", \"integrated_gradients\", \"lime\", \"deeplift\", \"gradient_shap\",\"discretized_integrated_gradients\"\n",
    "# attributed_fns = [\"logit\",\"probability\"] #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "# revs = [\"False\",\"True\"]\n",
    "# NORM = True\n",
    "# data = \"dna\"\n",
    "# # normalize = [\"True\", \"False\"]\n",
    "\n",
    "# model_inseq = inseq.load_model(\"gpt2\", explanation)\n",
    "\n",
    "# base_l = []\n",
    "# base_p = []\n",
    "\n",
    "# contrast_l_T = []\n",
    "# contrast_l_F = []\n",
    "# contrast_p_T = []\n",
    "# contrast_p_F = []\n",
    "\n",
    "# contrast_rnd_l_T = []\n",
    "# contrast_rnd_l_F = []\n",
    "# contrast_rnd_p_T = []\n",
    "# contrast_rnd_p_F = []\n",
    "\n",
    "\n",
    "\n",
    "# i = 0\n",
    "# for attributed_fn in attributed_fns:\n",
    "    \n",
    "#     base = False\n",
    "    \n",
    "#     if attributed_fn == 'logit':\n",
    "#         contrast_attributed_fn = \"contrast_logits_diff\"\n",
    "#     if attributed_fn == 'probability':\n",
    "#         contrast_attributed_fn = \"contrast_prob_diff\"\n",
    "        \n",
    "#     for rev in revs:\n",
    "# #         for sentence in sentences:\n",
    "# #             i += 1\n",
    "# #             print(i)\n",
    "# #             target = \"any\"\n",
    "# #             foil = \"some\"\n",
    "# #             foil_rnd = \"hello\"\n",
    "#         for index, row in dataframe_dna.iterrows():\n",
    "#             print(index)\n",
    "#             sentence = row[\"one_prefix_prefix\"]\n",
    "#             target = row[\"one_prefix_word_good\"]\n",
    "#             foil = row[\"one_prefix_word_bad\"]\n",
    "#             foil_rnd = \"hello\"\n",
    "            \n",
    "\n",
    "            \n",
    "#             if base == False:\n",
    "#                 baseline = model_inseq.attribute(\n",
    "#                     sentence,\n",
    "#                     sentence + \" \" + target,\n",
    "#                     attributed_fn=attributed_fn,\n",
    "#                 )\n",
    "                              \n",
    "\n",
    "#             contrast = model_inseq.attribute(\n",
    "#                 sentence,\n",
    "#                 sentence + \" \" + foil,\n",
    "#                 attributed_fn=attributed_fn,\n",
    "#             )\n",
    "\n",
    "#             contrast_rnd = model_inseq.attribute(\n",
    "#                 sentence,\n",
    "#                 sentence + \" \" + foil_rnd,\n",
    "#                 attributed_fn=attributed_fn,\n",
    "#             )\n",
    "                \n",
    "                       \n",
    "\n",
    "#             clear_output()\n",
    "\n",
    "#             base_tensor = baseline[0].target_attributions\n",
    "#             contrastive_tensor = contrast[0].target_attributions\n",
    "#             contrastive_rnd_tensor = contrast_rnd[0].target_attributions\n",
    "\n",
    "#             baseline_att = base_tensor.sum(axis = 2)\n",
    "#             contrast_att = contrastive_tensor.sum(axis = 2)\n",
    "#             contrast_rnd_att = contrastive_rnd_tensor.sum(axis = 2)\n",
    "            \n",
    "  \n",
    "\n",
    "# # ERASURE:\n",
    "# #             baseline_att = base_tensor\n",
    "# #             contrast_att = contrastive_tensor\n",
    "# #             contrast_rnd_att = contrastive_rnd_tensor\n",
    "\n",
    "#             baseline_att = torch.flatten(baseline_att[~torch.any(baseline_att.isnan(),dim=1)]).numpy()\n",
    "#             contrast_att = torch.flatten(contrast_att[~torch.any(contrast_att.isnan(),dim=1)]).numpy()\n",
    "#             contrast_rnd_att = torch.flatten(contrast_rnd_att[~torch.any(contrast_rnd_att.isnan(),dim=1)]).numpy()\n",
    "\n",
    "# #             if NORM == True:\n",
    "# #                 baseline_att =  normalize_vector(baseline_att)\n",
    "# #                 contrast_att_norm = normalize_vector(contrast_att)\n",
    "# #                 contrast_rnd_att_norm = normalize_vector(contrast_rnd_att)\n",
    "                \n",
    "# #                 if rev == 'False':\n",
    "# #                     contrast_att = baseline_att- contrast_att_norm\n",
    "# #                     contrast_rnd_att = baseline_att - contrast_rnd_att_norm\n",
    "# #                 elif rev == 'True':\n",
    "# #                     contrast_att = contrast_att_norm - baseline_att\n",
    "# #                     contrast_rnd_att = contrast_rnd_att_norm -baseline_att\n",
    "                \n",
    "                \n",
    "                \n",
    "#             if data == \"any\":\n",
    "#                 targets = get_target(sentence)\n",
    "#             elif data == \"npi\":\n",
    "#                 sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "#                 targets = [True] + [False] * (sent_len - 1)\n",
    "#             elif data == \"dna\":\n",
    "#                 sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "#                 targets = [False] * (sent_len - 1)+[True]\n",
    "\n",
    "            \n",
    "#             base_mmr = reciprocal_rank(baseline_att, targets)\n",
    "#             contrast_mmr = reciprocal_rank(contrast_att, targets)\n",
    "#             contrast_rnd_mmr = reciprocal_rank(contrast_rnd_att, targets)\n",
    "            \n",
    "#             if rev == 'True':\n",
    "#                 if attributed_fn == 'logit':\n",
    "#                     contrast_l_T.append(contrast_mmr)\n",
    "#                     contrast_rnd_l_T.append(contrast_mmr)\n",
    "                    \n",
    "#                 elif attributed_fn == 'probability':\n",
    "#                     contrast_p_T.append(contrast_mmr)\n",
    "#                     contrast_rnd_p_T.append(contrast_mmr)\n",
    "                    \n",
    "#             elif rev == 'False':\n",
    "#                 if attributed_fn == 'logit':\n",
    "#                     base_l.append(base_mmr)\n",
    "#                     contrast_l_F.append(contrast_mmr)\n",
    "#                     contrast_rnd_l_F.append(contrast_mmr)\n",
    "                    \n",
    "#                 elif attributed_fn == 'probability':         \n",
    "#                     base_p.append(base_mmr)\n",
    "#                     contrast_p_F.append(contrast_mmr)\n",
    "#                     contrast_rnd_p_F.append(contrast_mmr)\n",
    "#         base = True\n",
    "\n",
    "                            \n",
    "\n",
    "\n",
    "\n",
    "# results = {'base_l':base_l,'base_p':base_p,'contrast_l_T':contrast_l_T,'contrast_l_F':contrast_l_F,'contrast_p_T':contrast_p_T,\n",
    "#            'contrast_p_F':contrast_p_F,'contrast_rnd_l_T':contrast_rnd_l_T,'contrast_rnd_l_F':contrast_rnd_l_F,'contrast_rnd_p_T':contrast_rnd_p_T\n",
    "#            ,'contrast_rnd_p_F':contrast_rnd_p_F}\n",
    "\n",
    "# dataframe_results_inputx = pd.DataFrame(data=results)\n",
    "# dataframe_results_inputx.to_csv(f'X_norm_all_{data}.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             if rev == 'False':\n",
    "#                 contrast = model_inseq.attribute(\n",
    "#                   sentence,\n",
    "#                   sentence + \" \" + target,\n",
    "#                   attributed_fn= contrast_attributed_fn,\n",
    "#                   contrast_targets= sentence + \" \" + foil,\n",
    "#                   step_scores=[contrast_attributed_fn]\n",
    "#                 )\n",
    "                \n",
    "#                 contrast_rnd = model_inseq.attribute(\n",
    "#                   sentence,\n",
    "#                   sentence + \" \" + target,\n",
    "#                   attributed_fn= contrast_attributed_fn,\n",
    "#                   contrast_targets= sentence + \" \" + foil_rnd,\n",
    "#                   step_scores=[contrast_attributed_fn]\n",
    "#                 )\n",
    "                \n",
    "#             if rev == 'True':\n",
    "#                 contrast = model_inseq.attribute(\n",
    "#                   sentence,\n",
    "#                   sentence + \" \" + foil,\n",
    "#                   attributed_fn= contrast_attributed_fn,\n",
    "#                   contrast_targets= sentence + \" \" + target,\n",
    "#                   step_scores=[contrast_attributed_fn]\n",
    "#                 )\n",
    "                \n",
    "#                 contrast_rnd = model_inseq.attribute(\n",
    "#                   sentence,\n",
    "#                   sentence + \" \" + foil_rnd,\n",
    "#                   attributed_fn= contrast_attributed_fn,\n",
    "#                   contrast_targets= sentence + \" \" + target,\n",
    "#                   step_scores=[contrast_attributed_fn]\n",
    "#                 )\n",
    "\n",
    "#@title #**Loop through 'ANY' NPI and give MRR**\n",
    "import torch\n",
    "explanation = \"input_x_gradient\" #\"input_x_gradient\", \"integrated_gradients\", \"lime\", \"deeplift\", \"gradient_shap\",\"discretized_integrated_gradients\"\n",
    "attributed_fns = [\"logit\",\"probability\"] #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "revs = [\"False\",\"True\"]\n",
    "NORM = True\n",
    "data = \"npi\"\n",
    "# normalize = [\"True\", \"False\"]\n",
    "\n",
    "model_inseq = inseq.load_model(\"gpt2\", explanation)\n",
    "\n",
    "base_l = []\n",
    "base_p = []\n",
    "\n",
    "contrast_l_T = []\n",
    "contrast_l_F = []\n",
    "contrast_p_T = []\n",
    "contrast_p_F = []\n",
    "\n",
    "contrast_rnd_l_T = []\n",
    "contrast_rnd_l_F = []\n",
    "contrast_rnd_p_T = []\n",
    "contrast_rnd_p_F = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "for attributed_fn in attributed_fns:\n",
    "    \n",
    "    base = False\n",
    "    \n",
    "    if attributed_fn == 'logit':\n",
    "        contrast_attributed_fn = \"contrast_logits_diff\"\n",
    "    if attributed_fn == 'probability':\n",
    "        contrast_attributed_fn = \"contrast_prob_diff\"\n",
    "        \n",
    "    for rev in revs:\n",
    "#         for sentence in sentences:\n",
    "#             i += 1\n",
    "#             print(i)\n",
    "#             target = \"any\"\n",
    "#             foil = \"some\"\n",
    "#             foil_rnd = \"hello\"\n",
    "        for index, row in dataframe_npi.iterrows():\n",
    "            print(index)\n",
    "            sentence = row[\"one_prefix_prefix\"]\n",
    "            target = row[\"one_prefix_word_good\"]\n",
    "            foil = row[\"one_prefix_word_bad\"]\n",
    "            foil_rnd = \"hello\"\n",
    "            \n",
    "\n",
    "            \n",
    "            if base == False:\n",
    "                baseline = model_inseq.attribute(\n",
    "                    sentence,\n",
    "                    sentence + \" \" + target,\n",
    "                    attributed_fn=attributed_fn,\n",
    "                )\n",
    "                              \n",
    "\n",
    "            contrast = model_inseq.attribute(\n",
    "                sentence,\n",
    "                sentence + \" \" + foil,\n",
    "                attributed_fn=attributed_fn,\n",
    "            )\n",
    "\n",
    "            contrast_rnd = model_inseq.attribute(\n",
    "                sentence,\n",
    "                sentence + \" \" + foil_rnd,\n",
    "                attributed_fn=attributed_fn,\n",
    "            )\n",
    "                \n",
    "                       \n",
    "\n",
    "            clear_output()\n",
    "\n",
    "            base_tensor = baseline[0].target_attributions\n",
    "            contrastive_tensor = contrast[0].target_attributions\n",
    "            contrastive_rnd_tensor = contrast_rnd[0].target_attributions\n",
    "\n",
    "            baseline_att = base_tensor.sum(axis = 2)\n",
    "            contrast_att = contrastive_tensor.sum(axis = 2)\n",
    "            contrast_rnd_att = contrastive_rnd_tensor.sum(axis = 2)\n",
    "            \n",
    "  \n",
    "\n",
    "# ERASURE:\n",
    "#             baseline_att = base_tensor\n",
    "#             contrast_att = contrastive_tensor\n",
    "#             contrast_rnd_att = contrastive_rnd_tensor\n",
    "\n",
    "            baseline_att = torch.flatten(baseline_att[~torch.any(baseline_att.isnan(),dim=1)]).numpy()\n",
    "            contrast_att = torch.flatten(contrast_att[~torch.any(contrast_att.isnan(),dim=1)]).numpy()\n",
    "            contrast_rnd_att = torch.flatten(contrast_rnd_att[~torch.any(contrast_rnd_att.isnan(),dim=1)]).numpy()\n",
    "\n",
    "            if NORM == True:\n",
    "                baseline_att =  normalize_vector(baseline_att)\n",
    "                contrast_att_norm = normalize_vector(contrast_att)\n",
    "                contrast_rnd_att_norm = normalize_vector(contrast_rnd_att)\n",
    "                \n",
    "                if rev == 'False':\n",
    "                    contrast_att = baseline_att- contrast_att_norm\n",
    "                    contrast_rnd_att = baseline_att - contrast_rnd_att_norm\n",
    "                elif rev == 'True':\n",
    "                    contrast_att = contrast_att_norm - baseline_att\n",
    "                    contrast_rnd_att = contrast_rnd_att_norm -baseline_att\n",
    "                \n",
    "                \n",
    "                \n",
    "            if data == \"any\":\n",
    "                targets = get_target(sentence)\n",
    "            elif data == \"npi\":\n",
    "                sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "                targets = [True] + [False] * (sent_len - 1)\n",
    "            elif data == \"dna\":\n",
    "                sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "                targets = [False] * (sent_len - 1)+[True]\n",
    "\n",
    "            \n",
    "            base_mmr = reciprocal_rank(baseline_att, targets)\n",
    "            contrast_mmr = reciprocal_rank(contrast_att, targets)\n",
    "            contrast_rnd_mmr = reciprocal_rank(contrast_rnd_att, targets)\n",
    "            \n",
    "            if rev == 'True':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_l_T.append(contrast_mmr)\n",
    "                    contrast_rnd_l_T.append(contrast_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':\n",
    "                    contrast_p_T.append(contrast_mmr)\n",
    "                    contrast_rnd_p_T.append(contrast_mmr)\n",
    "                    \n",
    "            elif rev == 'False':\n",
    "                if attributed_fn == 'logit':\n",
    "                    base_l.append(base_mmr)\n",
    "                    contrast_l_F.append(contrast_mmr)\n",
    "                    contrast_rnd_l_F.append(contrast_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':         \n",
    "                    base_p.append(base_mmr)\n",
    "                    contrast_p_F.append(contrast_mmr)\n",
    "                    contrast_rnd_p_F.append(contrast_mmr)\n",
    "        base = True\n",
    "\n",
    "                            \n",
    "\n",
    "\n",
    "\n",
    "results = {'base_l':base_l,'base_p':base_p,'contrast_l_T':contrast_l_T,'contrast_l_F':contrast_l_F,'contrast_p_T':contrast_p_T,\n",
    "           'contrast_p_F':contrast_p_F,'contrast_rnd_l_T':contrast_rnd_l_T,'contrast_rnd_l_F':contrast_rnd_l_F,'contrast_rnd_p_T':contrast_rnd_p_T\n",
    "           ,'contrast_rnd_p_F':contrast_rnd_p_F}\n",
    "\n",
    "dataframe_results_inputx = pd.DataFrame(data=results)\n",
    "dataframe_results_inputx.to_csv(f'X_norm_all_{data}.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate means\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "means = dataframe_results_inputx.mean()\n",
    "\n",
    "# Plot means\n",
    "ax = means.plot(kind='bar')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Means')\n",
    "plt.title('Means of DataFrame Columns')\n",
    "\n",
    "# Annotate bars with values\n",
    "for i, v in enumerate(means):\n",
    "    ax.text(i, v + 0.1, str(round(v, 2)), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "logits\n",
      "1\n",
      "logits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/scur0635.5617556/ipykernel_1591662/3751410710.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrast_attributed_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 baseline = erasure_scores(model, input_tokens, attention_ids,correct=CORRECT_ID,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                           attr_fn = contrast_attributed_fn, normalize= True)\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/home3/scur0635/Baseline_clusters/lm_saliency.py\u001b[0m in \u001b[0;36merasure_scores\u001b[0;34m(model, input_ids, input_mask, correct, foil, remove, normalize, attr_fn)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown attr_fn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_score\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0merased_score\u001b[0m \u001b[0;31m# higher score = lower confidence in correct = more influential input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "#@title #**Loop through 'ANY' NPI and give MRR**\n",
    "attributed_fns = [\"logit\",\"probability\"] #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "revs = [\"False\",\"True\"]\n",
    "\n",
    "\n",
    "base_l = []\n",
    "base_p = []\n",
    "\n",
    "contrast_l_T = []\n",
    "contrast_l_F = []\n",
    "contrast_p_T = []\n",
    "contrast_p_F = []\n",
    "\n",
    "contrast_rnd_l_T = []\n",
    "contrast_rnd_l_F = []\n",
    "contrast_rnd_p_T = []\n",
    "contrast_rnd_p_F = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for attributed_fn in attributed_fns:\n",
    "    \n",
    "    base = False\n",
    "    \n",
    "    if attributed_fn == 'logit':\n",
    "        contrast_attributed_fn = \"logits\"\n",
    "    if attributed_fn == 'probability':\n",
    "        contrast_attributed_fn = \"probabilities\"\n",
    "        \n",
    "    for rev in revs:\n",
    "        \n",
    "        for index, row in dataframe_dna.iterrows():\n",
    "            print(index)\n",
    "            sentence = row[\"one_prefix_prefix\"]\n",
    "            target = row[\"one_prefix_word_good\"]\n",
    "            foil = row[\"one_prefix_word_bad\"]\n",
    "            foil_rnd = \"hello\"\n",
    "#         for sentence in sentences:\n",
    "#             print(i)\n",
    "#             i += 1\n",
    "            \n",
    "#             target = \"any\"\n",
    "#             foil = \"some\"\n",
    "#             foil_rnd = \"hello\"\n",
    "\n",
    "#             input = sentence.strip() + \" \"\n",
    "            input_tokens = tokenizer(sentence)['input_ids']\n",
    "            attention_ids = tokenizer(sentence)['attention_mask']\n",
    "\n",
    "            CORRECT_ID = tokenizer(\" \"+ target)['input_ids']\n",
    "            FOIL_ID = tokenizer(\" \"+ foil)['input_ids']\n",
    "            FOIL_ID_RND = FOIL_ID = tokenizer(\" \"+ foil_rnd)['input_ids']\n",
    "\n",
    "            if base == False:\n",
    "                print(contrast_attributed_fn)\n",
    "                baseline = erasure_scores(model, input_tokens, attention_ids,correct=CORRECT_ID,\n",
    "                                          attr_fn = contrast_attributed_fn, normalize= True)\n",
    "\n",
    "\n",
    "            if rev == 'False':\n",
    "                contrast = erasure_scores(model, input_tokens, attention_ids, correct=CORRECT_ID,\n",
    "                                          foil=FOIL_ID, attr_fn = contrast_attributed_fn, normalize= True)\n",
    "                contrast_rnd = erasure_scores(model, input_tokens, attention_ids, correct=CORRECT_ID,\n",
    "                                              foil=FOIL_ID_RND, attr_fn = contrast_attributed_fn, normalize= True)\n",
    "                \n",
    "            elif rev == 'True':\n",
    "                \n",
    "                contrast = erasure_scores(model, input_tokens, attention_ids, correct=FOIL_ID, foil=CORRECT_ID,\n",
    "                                          attr_fn = contrast_attributed_fn, normalize= True)\n",
    "                contrast_rnd = erasure_scores(model, input_tokens, attention_ids, correct=FOIL_ID_RND,\n",
    "                                              foil=CORRECT_ID, attr_fn = contrast_attributed_fn, normalize= True)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "#             clear_output()\n",
    "\n",
    "\n",
    "#             targets = get_target(sentence)\n",
    "            sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "#             targets = [True] + [False] * (sent_len - 1)\n",
    "            targets = [False] * (sent_len - 1)+[True]\n",
    "\n",
    "            \n",
    "            base_mmr = reciprocal_rank(baseline, targets)\n",
    "            contrast_mmr = reciprocal_rank(contrast, targets)\n",
    "            contrast_rnd_mmr = reciprocal_rank(contrast_rnd, targets)\n",
    "\n",
    "            \n",
    "            if rev == 'True':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_l_T.append(contrast_mmr)\n",
    "                    contrast_rnd_l_T.append(contrast_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':\n",
    "                    contrast_p_T.append(contrast_mmr)\n",
    "                    contrast_rnd_p_T.append(contrast_mmr)\n",
    "                    \n",
    "            elif rev == 'False':\n",
    "                if attributed_fn == 'logit':\n",
    "                    base_l.append(base_mmr)\n",
    "                    contrast_l_F.append(contrast_mmr)\n",
    "                    contrast_rnd_l_F.append(contrast_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':         \n",
    "                    base_p.append(base_mmr)\n",
    "                    contrast_p_F.append(contrast_mmr)\n",
    "                    contrast_rnd_p_F.append(contrast_mmr)\n",
    "                            \n",
    "        break\n",
    "    break\n",
    "\n",
    "\n",
    "results = {'base_l':base_l,'base_p':base_p,'contrast_l_T':contrast_l_T,'contrast_l_F':contrast_l_F,'contrast_p_T':contrast_p_T,\n",
    "           'contrast_p_F':contrast_p_F,'contrast_rnd_l_T':contrast_rnd_l_T,'contrast_rnd_l_F':contrast_rnd_l_F,'contrast_rnd_p_T':contrast_rnd_p_T\n",
    "           ,'contrast_rnd_p_F':contrast_rnd_p_F}\n",
    "\n",
    "dataframe_results_inputx = pd.DataFrame(data=results)\n",
    "dataframe_results_inputx.to_csv('erasure_all_npi.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scur0635/.local/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/scur0635/.local/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(base_l))\n",
    "print(np.mean(contrast_l_F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate means\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "means = dataframe_results_inputx.mean()\n",
    "\n",
    "# Plot means\n",
    "ax = means.plot(kind='bar')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Means')\n",
    "plt.title('Means of DataFrame Columns')\n",
    "\n",
    "# Annotate bars with values\n",
    "for i, v in enumerate(means):\n",
    "    ax.text(i, v + 0.1, str(round(v, 2)), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only length-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/scur0635.5614334/ipykernel_1808665/3084766079.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 baseline = erasure_scores(model, input_tokens, attention_ids,correct=CORRECT_ID,\n\u001b[0m\u001b[1;32m     58\u001b[0m                                           normalize=False, remove = False, attr_fn = contrast_attributed_fn)\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/home3/scur0635/Baseline_clusters/lm_saliency.py\u001b[0m in \u001b[0;36merasure_scores\u001b[0;34m(model, input_ids, input_mask, correct, foil, remove, normalize, attr_fn)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0merased_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#HIER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_score\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0merased_score\u001b[0m \u001b[0;31m# higher score = lower confidence in correct = more influential input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "#@title #**Loop through 'ANY' NPI and give MRR**\n",
    "attributed_fns = [\"logit\",\"probability\"] #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "revs = [\"True\", \"False\"]\n",
    "\n",
    "\n",
    "base_l = []\n",
    "base_p = []\n",
    "\n",
    "contrast_l_T = []\n",
    "contrast_l_F = []\n",
    "contrast_p_T = []\n",
    "contrast_p_F = []\n",
    "\n",
    "contrast_rnd_l_T = []\n",
    "contrast_rnd_l_F = []\n",
    "contrast_rnd_p_T = []\n",
    "contrast_rnd_p_F = []\n",
    "\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for attributed_fn in attributed_fns:\n",
    "    \n",
    "    base = False\n",
    "    \n",
    "    if attributed_fn == 'logit':\n",
    "        contrast_attributed_fn = \"logit\"\n",
    "    if attributed_fn == 'probability':\n",
    "        contrast_attributed_fn = \"probs\"\n",
    "        \n",
    "    for rev in revs:\n",
    "        for index, row in dataframe_dna.iterrows():\n",
    "            print(index)\n",
    "            sentence = row[\"one_prefix_prefix\"]\n",
    "            target = row[\"one_prefix_word_good\"]\n",
    "            foil = row[\"one_prefix_word_bad\"]\n",
    "            foil_rnd = \"hello\"\n",
    "            \n",
    "#         for sentence in sentences:\n",
    "#             print(i)\n",
    "#             i += 1\n",
    "            \n",
    "#             target = \"any\"\n",
    "#             foil = \"some\"\n",
    "#             foil_rnd = \"hello\"\n",
    "\n",
    "            input = sentence.strip() + \" \"\n",
    "            input_tokens = tokenizer(input)['input_ids']\n",
    "            attention_ids = tokenizer(input)['attention_mask']\n",
    "\n",
    "            CORRECT_ID = tokenizer(\" \"+ target)['input_ids']\n",
    "            FOIL_ID = tokenizer(\" \"+ foil)['input_ids']\n",
    "            FOIL_ID_RND = FOIL_ID = tokenizer(\" \"+ foil_rnd)['input_ids']\n",
    "\n",
    "            if base == False:\n",
    "                baseline = erasure_scores(model, input_tokens, attention_ids,correct=CORRECT_ID,\n",
    "                                          normalize=False, remove = False, attr_fn = contrast_attributed_fn)\n",
    "\n",
    "\n",
    "            if rev == 'False':\n",
    "                contrast = erasure_scores(model, input_tokens, attention_ids, correct=CORRECT_ID,\n",
    "                                          foil=FOIL_ID, normalize=False, remove = False, attr_fn = contrast_attributed_fn)\n",
    "                contrast_rnd = erasure_scores(model, input_tokens, attention_ids, correct=CORRECT_ID,\n",
    "                                              foil=FOIL_ID_RND, normalize=False, remove = False, attr_fn = contrast_attributed_fn)\n",
    "                \n",
    "            if rev == 'True':\n",
    "                contrast = erasure_scores(model, input_tokens, attention_ids, correct=FOIL_ID, foil=CORRECT_ID,\n",
    "                                          normalize=False, remove = False, attr_fn = contrast_attributed_fn)\n",
    "                contrast_rnd = erasure_scores(model, input_tokens, attention_ids, correct=FOIL_ID_RND,\n",
    "                                              foil=CORRECT_ID, normalize=False, remove = False, attr_fn = contrast_attributed_fn)\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            clear_output()\n",
    "\n",
    "\n",
    "#             targets = get_target(sentence)\n",
    "            sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "#             targets = [True] + [False] * (sent_len - 1)\n",
    "            targets = [False] * (sent_len - 1)+[True]\n",
    "\n",
    "            \n",
    "            base_mmr = reciprocal_rank(baseline, targets)\n",
    "            contrast_mmr = reciprocal_rank(contrast, targets)\n",
    "            contrast_rnd_mmr = reciprocal_rank(contrast_rnd, targets)\n",
    "            \n",
    "            if rev == 'True':\n",
    "                if attributed_fn == 'logit':\n",
    "                    contrast_l_T.append(contrast_mmr)\n",
    "                    contrast_rnd_l_T.append(contrast_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':\n",
    "                    contrast_p_T.append(contrast_mmr)\n",
    "                    contrast_rnd_p_T.append(contrast_mmr)\n",
    "                    \n",
    "            elif rev == 'False':\n",
    "                if attributed_fn == 'logit':\n",
    "                    base_l.append(base_mmr)\n",
    "                    contrast_l_F.append(contrast_mmr)\n",
    "                    contrast_rnd_l_F.append(contrast_mmr)\n",
    "                    \n",
    "                elif attributed_fn == 'probability':         \n",
    "                    base_p.append(base_mmr)\n",
    "                    contrast_p_F.append(contrast_mmr)\n",
    "                    contrast_rnd_p_F.append(contrast_mmr)\n",
    "                            \n",
    "\n",
    "\n",
    "\n",
    "results = {'base_l':base_l,'base_p':base_p,'contrast_l_T':contrast_l_T,'contrast_l_F':contrast_l_F,'contrast_p_T':contrast_p_T,\n",
    "           'contrast_p_F':contrast_p_F,'contrast_rnd_l_T':contrast_rnd_l_T,'contrast_rnd_l_F':contrast_rnd_l_F,'contrast_rnd_p_T':contrast_rnd_p_T\n",
    "           ,'contrast_rnd_p_F':contrast_rnd_p_F}\n",
    "\n",
    "dataframe_results_inputx = pd.DataFrame(data=results)\n",
    "dataframe_results_inputx.to_csv('erasure_all_dna.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate means\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "means = dataframe_results_inputx.mean()\n",
    "\n",
    "# Plot means\n",
    "ax = means.plot(kind='bar')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Means')\n",
    "plt.title('Means of DataFrame Columns')\n",
    "\n",
    "# Annotate bars with values\n",
    "for i, v in enumerate(means):\n",
    "    ax.text(i, v + 0.1, str(round(v, 2)), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bv3rgH4LeNW2"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "pbPeYdoQdsbP"
   },
   "outputs": [],
   "source": [
    "#@title #**Data:** load in NPI from BLIMP\n",
    "dataset = 'any' #@param['blimp', 'any']\n",
    "\n",
    "filename = \"prefix+value.tsv\" #@param [\"npi_present_1\", \"determiner_noun_agreement_1\",\"prefix+value.tsv\"]\n",
    "\n",
    "if location == 'colab':\n",
    "  filename = \"/content/drive/MyDrive/Thesis_Contrastive/\"+ filename\n",
    "\n",
    "if dataset == 'blimp':\n",
    "  with jsonlines.open(filename + \".jsonl\", 'r') as f:\n",
    "      dataframe = pd.DataFrame(f)\n",
    "\n",
    "if dataset == 'any':\n",
    "  sentences = []\n",
    "  values = []\n",
    "  with open(\"prefix+value.tsv\", 'r', encoding='utf-8') as ifh:\n",
    "      for line in ifh:\n",
    "          sentence, value = line.strip().split('\\t')\n",
    "          sentences.append(sentence)\n",
    "          values.append(value)\n",
    "  print(sentence,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "oI64ayv-3HqJ"
   },
   "outputs": [],
   "source": [
    "#@title #**Data:** Show data\n",
    "if dataset == 'any':\n",
    "  dit = []\n",
    "  b = False\n",
    "  for sentence in sentences:\n",
    "    booleans = get_target(sentence)\n",
    "    i = 1\n",
    "    b = False\n",
    "    for boole in booleans:\n",
    "      if boole:\n",
    "        b = True\n",
    "      if not boole and b:\n",
    "        i +=1\n",
    "    dit.append(i)\n",
    "\n",
    "  lengths = dit\n",
    "\n",
    "  plt.hist(lengths, bins=20, color='blue', edgecolor='black', align='mid')\n",
    "\n",
    "  # Adding labels and title\n",
    "  plt.xlabel('Lengths')\n",
    "  plt.ylabel('Frequency')\n",
    "  plt.title('Distribution of Lengths')\n",
    "  plt.xticks(range(0, 6))\n",
    "\n",
    "  # Display the plot\n",
    "  plt.savefig('data_dist', dpi = 800)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aV2ebBTWeT73"
   },
   "source": [
    "# Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIME TESTS FOR BASE VS CONT FEATURE ATTRIBUTION RAW SCORE COMPARISON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title #**Loop through 'ANY' NPI and give MRR**\n",
    "import torch\n",
    "explanations = [\"lime\"] #\"input_x_gradient\", \"integrated_gradients\", \"lime\", \"deeplift\", \"gradient_shap\",\"discretized_integrated_gradients\"\n",
    "attributed_fn = \"logit\" #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "# rev = 'False'\n",
    "normalize = 'True'\n",
    "\n",
    "base_l= []\n",
    "contrast_l = []\n",
    "contrast_rnd_l = []\n",
    "\n",
    "lime_base_l= []\n",
    "lime_contrast_l = []\n",
    "lime_contrast_rnd_l = []\n",
    "\n",
    "for indexer in [\"0\",\"-1\",\"start_ev\",\"'t'\"]:\n",
    "\n",
    "    for explanation in explanations:\n",
    "      gc.collect()\n",
    "      model_inseq = inseq.load_model(\"gpt2\", explanation)\n",
    "\n",
    "      base_l= []\n",
    "      contrast_l = []\n",
    "      contrast_rnd_l = []\n",
    "\n",
    "      i = 0\n",
    "      for sentence in sentences:\n",
    "        i += 1\n",
    "\n",
    "        target = \"any\"\n",
    "        foil = \"some\"\n",
    "        foil_rnd = \"hello\"\n",
    "\n",
    "        baseline = model_inseq.attribute(\n",
    "            sentence,\n",
    "            sentence + \" \" + target,\n",
    "            attributed_fn=attributed_fn,\n",
    "        )\n",
    "\n",
    "        contrast = model_inseq.attribute(\n",
    "            sentence,\n",
    "            sentence + \" \" + foil,\n",
    "            attributed_fn=attributed_fn,\n",
    "        )\n",
    "\n",
    "        contrast_rnd = model_inseq.attribute(\n",
    "            sentence,\n",
    "            sentence + \" \" + foil_rnd,\n",
    "            attributed_fn=attributed_fn,\n",
    "        )\n",
    "\n",
    "        clear_output()\n",
    "        print(f'{explanation} {i}')\n",
    "\n",
    "        base_tensor = baseline[0].target_attributions\n",
    "        contrastive_tensor = contrast[0].target_attributions\n",
    "        contrastive_rnd_tensor = contrast_rnd[0].target_attributions\n",
    "\n",
    "        baseline_att = base_tensor.sum(axis = 2)\n",
    "        contrast_att = contrastive_tensor.sum(axis = 2)\n",
    "        contrast_rnd_att = contrastive_rnd_tensor.sum(axis = 2)\n",
    "\n",
    "        baseline_att = torch.flatten(baseline_att[~torch.any(baseline_att.isnan(),dim=1)]).numpy()\n",
    "        contrast_att = torch.flatten(contrast_att[~torch.any(contrast_att.isnan(),dim=1)]).numpy()\n",
    "        contrast_rnd_att = torch.flatten(contrast_rnd_att[~torch.any(contrast_rnd_att.isnan(),dim=1)]).numpy()\n",
    "\n",
    "\n",
    "\n",
    "        targets = get_target(sentence)\n",
    "        \n",
    "        if indexer == \"-1\":\n",
    "            index = -1\n",
    "        elif indexer == \"0\":\n",
    "            index = 0\n",
    "        elif indexer == \"start_ev\":\n",
    "            index = targets.index(True)\n",
    "        elif indexer == \"'t\":\n",
    "            index = index = get_last_true_index(targets)\n",
    "\n",
    "        if normalize == 'True':\n",
    "            baseline_att_normal = normalize_vector(baseline_att)\n",
    "            contrast_att_normal = normalize_vector(contrast_att)\n",
    "            contrast_rnd_att_normal = normalize_vector(contrast_rnd_att)    \n",
    "\n",
    "            base_value = baseline_att_normal[index]\n",
    "            contrast_value = contrast_att_normal[index]\n",
    "            contrast_rnd_value = contrast_rnd_att_normal[index]   \n",
    "\n",
    "        else:\n",
    "            base_value = baseline_att[index]\n",
    "            contrast_value = contrast_att[index]\n",
    "            contrast_rnd_value = contrast_rnd_att[index]\n",
    "\n",
    "        base_l.append(base_value)\n",
    "        contrast_l.append(contrast_value)\n",
    "        contrast_rnd_l.append(contrast_rnd_value)\n",
    "        \n",
    "    dataframe_results_inputx = pd.DataFrame(data={'sentences':sentences, 'base':base_l, 'contrast':contrast_l, 'contrast_rnd': contrast_rnd_l})\n",
    "    dataframe_results_inputx.to_csv(f'input_x_gradient_raws_n_{indexer}.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_results_inputx = pd.DataFrame(data={'sentences':sentences, 'base':base_l, 'contrast':contrast_l, 'contrast_rnd': contrast_rnd_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataframe_results_inputx.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_results_inputx.to_csv('input_x_gradient_raws_n_start_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AonoYT2A0DhV",
    "outputId": "5854bc0a-41a6-44ec-fbc5-e1f670e719e8"
   },
   "outputs": [],
   "source": [
    "#@title #**Loop through 'ANY' NPI and give MRR**\n",
    "import torch\n",
    "explanations = [\"lime\"] #\"input_x_gradient\", \"integrated_gradients\", \"lime\", \"deeplift\", \"gradient_shap\",\"discretized_integrated_gradients\"\n",
    "attributed_fn = \"logit\" #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "rev = 'False'\n",
    "Results = {'Method': [], 'class':[], 'MRR': [], 'Dist': []}\n",
    "\n",
    "full_baselines = {\"input_x_gradient\":[], \"integrated_gradients\":[], \"lime\":[], \"deeplift\":[], \"gradient_shap\":[],\"discretized_integrated_gradients\":[]}\n",
    "full_contrastive= {\"input_x_gradient\":[], \"integrated_gradients\":[], \"lime\":[], \"deeplift\":[], \"gradient_shap\":[],\"discretized_integrated_gradients\":[]}\n",
    "\n",
    "full_baselines_org = {\"input_x_gradient\":[], \"integrated_gradients\":[], \"lime\":[], \"deeplift\":[], \"gradient_shap\":[],\"discretized_integrated_gradients\":[]}\n",
    "full_contrastive_org= {\"input_x_gradient\":[], \"integrated_gradients\":[], \"lime\":[], \"deeplift\":[], \"gradient_shap\":[],\"discretized_integrated_gradients\":[]}\n",
    "\n",
    "\n",
    "\n",
    "for explanation in explanations:\n",
    "\n",
    "  gc.collect()\n",
    "  model_inseq = inseq.load_model(\"gpt2\", explanation)\n",
    "\n",
    "\n",
    "  baseline_ranks = []\n",
    "  contrastive_ranks = []\n",
    "  dist = []\n",
    "  i = 0\n",
    "  for sentence in sentences:\n",
    "    i += 1\n",
    "    target = \"any\"\n",
    "    foil = \"some\"\n",
    "\n",
    "    baseline = model_inseq.attribute(\n",
    "        sentence,\n",
    "        sentence + \" \" + target,\n",
    "        attributed_fn=attributed_fn,\n",
    "    )\n",
    "\n",
    "    contrast = model_inseq.attribute(\n",
    "        sentence,\n",
    "        sentence + \" \" + foil,\n",
    "        attributed_fn=attributed_fn,\n",
    "    )\n",
    "\n",
    "    clear_output()\n",
    "    print(f'{explanation} {i}')\n",
    "#     sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "\n",
    "    base_tensor = baseline[0].target_attributions\n",
    "    contrastive_tensor = contrast[0].target_attributions\n",
    "\n",
    "\n",
    "    baseline_att = base_tensor.sum(axis = 2)\n",
    "    contrast_att = contrastive_tensor.sum(axis = 2)\n",
    "    baseline_att = torch.flatten(baseline_att[~torch.any(baseline_att.isnan(),dim=1)]).numpy()\n",
    "    contrast_att = torch.flatten(contrast_att[~torch.any(contrast_att.isnan(),dim=1)]).numpy()\n",
    "\n",
    "\n",
    "#     if filename == 'determiner_noun_agreement_1':\n",
    "#       targets = [False] * (sent_len - 1)+[True]\n",
    "#     else:\n",
    "#       targets = [True] + [False] * (sent_len - 1)\n",
    "\n",
    "#     baseline_att = baseline_att[:len(targets)]\n",
    "#     contrast_att = contrast_att[:len(targets)]\n",
    "    targets = get_target(sentence)\n",
    "\n",
    "    if rev == 'True':\n",
    "      contrastive_attributions = contrast_att- baseline_att\n",
    "    if rev == 'False':\n",
    "      contrastive_attributions = baseline_att-contrast_att\n",
    "\n",
    "    rank_baseline = reciprocal_rank(baseline_att, targets)\n",
    "    rank_contrastive = reciprocal_rank(contrastive_attributions, targets)\n",
    "\n",
    "    assert len(targets) == len(baseline_att), f'Target/Baseline mismatch \\n targets = {targets},\\n baseline_att = {baseline_att}'\n",
    "    assert len(targets) == len(contrastive_attributions), f'Target/Contrast mismatch {targets}, {contrast_att}'\n",
    "    assert len(contrastive_attributions) == len(baseline_att), f'Baseline/Contrast mismatch {baseline_att}, {contrast_att}'\n",
    "\n",
    "    baseline_ranks.append(rank_baseline)\n",
    "    contrastive_ranks.append(rank_contrastive)\n",
    "    dist.append(len(targets))\n",
    "\n",
    "  if rev == 'True':\n",
    "      full_baselines[explanation] = baseline_ranks\n",
    "      full_contrastive[explanation] = contrastive_ranks\n",
    "  if rev == 'False':\n",
    "      full_baselines_org[explanation] = baseline_ranks\n",
    "      full_contrastive_org[explanation] = contrastive_ranks\n",
    "\n",
    "  AVG_dist = average(dist)\n",
    "  MRR_baseline = average(baseline_ranks)\n",
    "  MRR_contrastive = average(contrastive_ranks)\n",
    "\n",
    "\n",
    "  Results['Method'].append(explanation)\n",
    "  Results['Method'].append(explanation)\n",
    "\n",
    "  Results['class'].append('baseline')\n",
    "  Results['class'].append('contrastive')\n",
    "\n",
    "  Results['MRR'].append(MRR_baseline)\n",
    "  Results['MRR'].append(MRR_contrastive)\n",
    "\n",
    "  Results['Dist'].append(AVG_dist)\n",
    "  Results['Dist'].append(AVG_dist)\n",
    "\n",
    "  print(Results)\n",
    "dataframe_results = pd.DataFrame(data=Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"limeS_cont.json\", 'w') as flie:\n",
    "  json.dump(full_contrastive_org,flie)\n",
    "with open(\"limeS_base.json\", 'w') as flie:\n",
    "  json.dump(full_baselines_org,flie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "0ZmCnzIt0A8d"
   },
   "outputs": [],
   "source": [
    "#@title #**Erasure, gradient norm for 'any'**\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "baseline_ranks_org = []\n",
    "contrastive_ranks_org = []\n",
    "dist = []\n",
    "i = 0\n",
    "\n",
    "for sentence in sentences:\n",
    "  input = sentence\n",
    "  input_tokens = tokenizer(input)['input_ids']\n",
    "  attention_ids = tokenizer(input)['attention_mask']\n",
    "\n",
    "\n",
    "  target = \"any\"\n",
    "  foil = \"some\"\n",
    "  CORRECT_ID = tokenizer(\" \"+ target)['input_ids']\n",
    "  FOIL_ID = tokenizer(\" \"+ foil)['input_ids']\n",
    "\n",
    "  # Erasure\n",
    "  base_explanation = erasure_scores(model, input_tokens, attention_ids,correct=CORRECT_ID, normalize=True)\n",
    "  contra_explanation = erasure_scores(model, input_tokens, attention_ids, correct=CORRECT_ID, foil=FOIL_ID, normalize=True)\n",
    "\n",
    "  targets = get_target(sentence)\n",
    "\n",
    "  rank_baseline = reciprocal_rank(base_explanation, targets)\n",
    "  rank_contrastive = reciprocal_rank(contra_explanation, targets)\n",
    "  baseline_ranks_org.append(rank_baseline)\n",
    "  contrastive_ranks_org.append(rank_contrastive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bpTb1Lo2fAmC"
   },
   "outputs": [],
   "source": [
    "#@title #**Erasure, gradient norm for 'blimp'**\n",
    "\n",
    "baseline_ranks = []\n",
    "contrastive_ranks_org = []\n",
    "contrastive_ranks = []\n",
    "random_ranks = []\n",
    "kayo = []\n",
    "kayo_rev = []\n",
    "\n",
    "dist = []\n",
    "i = 0\n",
    "\n",
    "\n",
    "for index, row in dataframe.iterrows():\n",
    "  print(index)\n",
    "  clear_output()\n",
    "  input = row[\"one_prefix_prefix\"]\n",
    "  target = row[\"one_prefix_word_good\"]\n",
    "  foil = row[\"one_prefix_word_bad\"]\n",
    "\n",
    "\n",
    "  # input = sentence\n",
    "  input_tokens = tokenizer(input)['input_ids']\n",
    "  attention_ids = tokenizer(input)['attention_mask']\n",
    "\n",
    "  CORRECT_ID = tokenizer(\" \"+ target)['input_ids']\n",
    "  FOIL_ID = tokenizer(\" \"+ foil)['input_ids']\n",
    "\n",
    "  # Erasure\n",
    "  base_explanation       = erasure_scores(model, input_tokens, attention_ids, correct=CORRECT_ID, normalize=True)\n",
    "  contra_explanation_org = erasure_scores(model, input_tokens, attention_ids, correct=CORRECT_ID, foil=FOIL_ID, normalize=True)\n",
    "  contra_explanation     = erasure_scores(model, input_tokens, attention_ids, correct=FOIL_ID, foil=CORRECT_ID, normalize=True)\n",
    "  contra_explanation_kayo_rev = erasure_scores(model, input_tokens, attention_ids, foil=CORRECT_ID, normalize=True)\n",
    "  contra_explanation_kayo = erasure_scores(model, input_tokens, attention_ids, foil=FOIL_ID, normalize=True)\n",
    "\n",
    "\n",
    "  sent_len = len(tokenizer(input)['input_ids'])\n",
    "  targets = [True] + [False] * (sent_len - 1)\n",
    "\n",
    "  random_expl =  generate_one_hot_list(len(targets))\n",
    "\n",
    "  rank_baseline = reciprocal_rank(base_explanation, targets)\n",
    "  rank_contrastive = reciprocal_rank(contra_explanation, targets)\n",
    "  rank_contrastive_org = reciprocal_rank(contra_explanation_org, targets)\n",
    "  rank_random = reciprocal_rank(random_expl, targets)\n",
    "  rank_contra_explanation_kayo_rev = reciprocal_rank(contra_explanation_kayo_rev, targets)\n",
    "  rank_contra_explanation_kayo= reciprocal_rank(contra_explanation_kayo, targets)\n",
    "\n",
    "\n",
    "  baseline_ranks.append(rank_baseline)\n",
    "  contrastive_ranks_org.append(rank_contrastive_org)\n",
    "  contrastive_ranks.append(rank_contrastive)\n",
    "  random_ranks.append(rank_random)\n",
    "  kayo.append(rank_contra_explanation_kayo)\n",
    "  kayo_rev.append(rank_contra_explanation_kayo_rev)\n",
    "\n",
    "\n",
    "erasure_dict = {\"erasure_base\": baseline_ranks, \"erasure_contrast_org\": contrastive_ranks_org, \"erasure_contrast\":contrastive_ranks, \"random\":random_ranks, \"erasure_kayo_rev\": kayo_rev, \"erasure_kayo\": kayo }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYaIDEEgx4KW"
   },
   "outputs": [],
   "source": [
    "if location == 'colab':\n",
    "  with open('/content/drive/MyDrive/Thesis_Contrastive/full_baselines_org.json', 'r') as ifh:\n",
    "    full_baselines = json.load(ifh)\n",
    "\n",
    "  with open('/content/drive/MyDrive/Thesis_Contrastive/full_contrastive_org.json', 'r') as ofh:\n",
    "      full_contrastive = json.load(ofh)\n",
    "\n",
    "else:\n",
    "  with open('full_baselines.json', 'r') as ifh:\n",
    "      full_baselines = json.load(ifh)\n",
    "\n",
    "  with open('full_contrastive.json', 'r') as ofh:\n",
    "      full_contrastive = json.load(ofh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hb6xa-EC9cHV"
   },
   "outputs": [],
   "source": [
    " with open('/content/drive/MyDrive/Thesis_Contrastive/random.json', 'r') as ifh:\n",
    "    random = json.load(ifh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BVmOXjV9naT"
   },
   "outputs": [],
   "source": [
    "random = {'random': random}\n",
    "random_frame = pd.DataFrame.from_dict(random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cAWHBESj9s4H"
   },
   "outputs": [],
   "source": [
    "random_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DeLJwShIx4KW"
   },
   "outputs": [],
   "source": [
    "# del full_baselines['discretized_integrated_gradients']\n",
    "# del full_contrastive['discretized_integrated_gradients']\n",
    "\n",
    "key_mapping_base = {'input_x_gradient': 'input_x_gradient_base_org', 'integrated_gradients': 'integrated_gradients_base_org', 'lime': 'lime_base_org', 'deeplift': 'deeplift_base_org', 'gradient_shap': 'gradient_shap_base_org'}\n",
    "full_baselines = {key_mapping_base.get(old_key, old_key): value for old_key, value in full_baselines.items()}\n",
    "\n",
    "key_mapping_cont = {'input_x_gradient': 'input_x_gradient_contrast_org', 'integrated_gradients': 'integrated_gradients_contrast_org', 'lime': 'lime_contrast_org', 'deeplift': 'deeplift_contrast_org', 'gradient_shap': 'gradient_shap_contrast_org'}\n",
    "full_contrastive = {key_mapping_cont.get(old_key, old_key): value for old_key, value in full_contrastive.items()}\n",
    "\n",
    "baseline_frame_org = pd.DataFrame.from_dict(full_baselines)\n",
    "contrastive_frame_org = pd.DataFrame.from_dict(full_contrastive)\n",
    "\n",
    "# Concatenate DataFrames\n",
    "merged_df = pd.concat([baseline_frame, contrastive_frame])\n",
    "\n",
    "# Display the merged DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wopVNMyxGrZQ"
   },
   "outputs": [],
   "source": [
    "erasure_frame = pd.DataFrame.from_dict(erasure_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "lC33SqCeiKay"
   },
   "outputs": [],
   "source": [
    "erasure_frame.to_csv('Results_erasure.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "hY5Q4ppmG44r",
    "outputId": "123133f1-7dfc-4542-85d9-86383d48c035"
   },
   "outputs": [],
   "source": [
    "base = erasure_frame['erasure_base'].mean()\n",
    "contrast = erasure_frame['erasure_contrast'].mean()\n",
    "contrast_org = erasure_frame['erasure_contrast_org'].mean()\n",
    "kayoyin = erasure_frame['erasure_kayo'].mean()\n",
    "kayoyin_rev = erasure_frame['erasure_kayo_rev'].mean()\n",
    "\n",
    "randomzz = erasure_frame['random'].mean()\n",
    "\n",
    "print(base, contrast, contrast_org, randomzz,kayoyin,kayoyin_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgJlohMIO7CX"
   },
   "outputs": [],
   "source": [
    "merged_df = pd.concat([ random_frame,baseline_frame, contrastive_frame, baseline_frame_org,contrastive_frame_org ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "5rwRXq4QyTod",
    "outputId": "b8b84fb1-3ceb-4ad0-9830-b7dd5f6ee522"
   },
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "toFayQTd0QH3"
   },
   "outputs": [],
   "source": [
    "merged_df.to_csv('Results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Axnm054Bx4KW",
    "outputId": "64137268-cef2-47a7-ae48-f37a81542247"
   },
   "outputs": [],
   "source": [
    "# Zip and sort based on x_values\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "rev = 'True' #@param['True', 'False']\n",
    "\n",
    "if rev == 'True':\n",
    "  with open(\"/content/drive/MyDrive/Thesis_Contrastive/full_contrastive.json\", 'r') as flie:\n",
    "    contrastive = json.load(flie)\n",
    "  with open(\"/content/drive/MyDrive/Thesis_Contrastive/full_baselines.json\", 'r') as flie:\n",
    "    baselines = json.load(flie)\n",
    "if rev == 'False':\n",
    "  with open(\"/content/drive/MyDrive/Thesis_Contrastive/full_contrastive_org.json\", 'r') as flie:\n",
    "    contrastive = json.load(flie)\n",
    "  with open(\"/content/drive/MyDrive/Thesis_Contrastive/full_baselines_org.json\", 'r') as flie:\n",
    "    baselines = json.load(flie)\n",
    "\n",
    "with open(\"/content/drive/MyDrive/Thesis_Contrastive/random.json\", 'r') as flie:\n",
    "  random_ranks = json.load(flie)\n",
    "\n",
    "sentences = []\n",
    "values = []\n",
    "with open(\"/content/drive/MyDrive/Thesis_Contrastive/prefix+value.tsv\", 'r', encoding='utf-8') as ifh:\n",
    "    for line in ifh:\n",
    "        sentence, value = line.strip().split('\\t')\n",
    "        sentences.append(sentence)\n",
    "        values.append(value)\n",
    "print(sentence,value)\n",
    "\n",
    "\n",
    "method = 'input_x_gradient' #@param ['input_x_gradient','integrated_gradients' ,'deeplift' , 'lime', 'gradient_shap', 'erasure']\n",
    "\n",
    "values = [float(x) for x in values]\n",
    "sorted_data = sorted(zip(values, random_ranks, baselines[method], contrastive[method]), key=lambda x: x[0])\n",
    "x_sorted, random_baselines,y1_sorted, y2_sorted = zip(*sorted_data)\n",
    "\n",
    "\n",
    "# Plotting with smaller dots\n",
    "window_size = 50\n",
    "y1_averages = np.convolve(y1_sorted, np.ones(window_size)/window_size, mode='valid')\n",
    "y2_averages = np.convolve(y2_sorted, np.ones(window_size)/window_size, mode='valid')\n",
    "y3_averages = np.convolve(random_baselines, np.ones(window_size)/window_size, mode='valid')\n",
    "x_averages = np.convolve(x_sorted, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "# Fit polynomial trendlines\n",
    "degree = 1  # You can adjust the degree of the polynomial\n",
    "z1 = np.polyfit(x_averages, y1_averages, degree)\n",
    "z2 = np.polyfit(x_averages, y2_averages, degree)\n",
    "z3 = np.polyfit(x_averages, y3_averages, degree)\n",
    "\n",
    "# Create polynomial functions\n",
    "p1 = np.poly1d(z1)\n",
    "p2 = np.poly1d(z2)\n",
    "p3 = np.poly1d(z3)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.scatter(x_averages[:len(y1_averages)], y1_averages, label='Baseline MRR per 50 points', s=5)\n",
    "plt.scatter(x_averages[:len(y2_averages)], y2_averages, label='Contrastive MRR per 50 points', s=5)\n",
    "\n",
    "\n",
    "# Plot trendlines\n",
    "plt.plot(x_averages, p1(x_averages), label='Trendline Baseline', color='purple')\n",
    "plt.plot(x_averages, p2(x_averages), label='Trendline Contrastive', color='red')\n",
    "plt.plot(x_averages, p3(x_averages), label='Trendline Random Baseline', color='yellow')\n",
    "\n",
    "# Adding labels and legend\n",
    "plt.xlabel('Perplexity difference between \"some\" and \"any\". Higher is better.')\n",
    "plt.ylabel('RR')\n",
    "plt.legend(fontsize = 7)\n",
    "plt.title(f'{method} Baseline vs Contrastive on \"ANY\" dataset.')\n",
    "# Set a higher resolution (dpi) for the plot\n",
    "plt.savefig('scatter_plot_averages.png', dpi=400)  # Adjust the filename and dpi as needed\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O6AlO5vVx4KX",
    "outputId": "1b3bba71-544a-495a-dbb0-b6195a863062"
   },
   "outputs": [],
   "source": [
    "#Random Baseline\n",
    "\n",
    "#@title #**Loop through blimp NPI and give MRR**\n",
    "import torch\n",
    "explanation = 'random'\n",
    "attributed_fn = \"logit\" #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "rev = 'True'\n",
    "Results = {'Method': [], 'class':[], 'MRR': [], 'Dist': []}\n",
    "random_ranks = []\n",
    "for sentence in sentences:\n",
    "\n",
    "  targets = get_target(sentence)\n",
    "  baseline_att =  generate_one_hot_list(len(targets))\n",
    "\n",
    "  rank_random = reciprocal_rank(baseline_att, targets)\n",
    "\n",
    "  random_ranks.append(rank_random)\n",
    "\n",
    "\n",
    "MRR_baseline = average(random_ranks)\n",
    "\n",
    "\n",
    "print(MRR_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bmc1zNfWcFB8"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/Thesis_Contrastive/random.json\", 'w') as flie:\n",
    "  json.dump(random_ranks,flie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PBpkfLGx4KX"
   },
   "outputs": [],
   "source": [
    "#LIME ONLY\n",
    "\n",
    "import torch\n",
    "explanations = [\"lime\"] #\"input_x_gradient\", \"integrated_gradients\", \"lime\", \"deeplift\", \"gradient_shap\",\"discretized_integrated_gradients\"\n",
    "attributed_fn = \"logit\" #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "rev = 'True'\n",
    "Results = {'Method': [], 'class':[], 'MRR': [], 'Dist': []}\n",
    "full_baselines = {\"input_x_gradient\":[], \"integrated_gradients\":[], \"lime\":[], \"deeplift\":[], \"gradient_shap\":[],\"discretized_integrated_gradients\":[]}\n",
    "full_contrastive= {\"input_x_gradient\":[], \"integrated_gradients\":[], \"lime\":[], \"deeplift\":[], \"gradient_shap\":[],\"discretized_integrated_gradients\":[]}\n",
    "for explanation in explanations:\n",
    "\n",
    "  gc.collect()\n",
    "  model_inseq = inseq.load_model(\"gpt2\", explanation)\n",
    "\n",
    "\n",
    "  baseline_ranks = []\n",
    "  contrastive_ranks = []\n",
    "  dist = []\n",
    "  i = 0\n",
    "  for sentence in sentences:\n",
    "    i += 1\n",
    "    target = \"any\"\n",
    "    foil = \"some\"\n",
    "\n",
    "    baseline = model_inseq.attribute(\n",
    "        sentence,\n",
    "        sentence + \" \" + target,\n",
    "        attributed_fn=attributed_fn,\n",
    "    )\n",
    "\n",
    "    contrast = model_inseq.attribute(\n",
    "        sentence,\n",
    "        sentence + \" \" + foil,\n",
    "        attributed_fn='contrast_logits_diff',\n",
    "        contrast_targets=sentence + \" \"+target,\n",
    "    )\n",
    "\n",
    "    clear_output()\n",
    "    print(f'{explanation} {i}')\n",
    "#     sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "\n",
    "    base_tensor = baseline[0].target_attributions\n",
    "    contrastive_tensor = contrast[0].target_attributions\n",
    "\n",
    "\n",
    "    baseline_att = base_tensor.sum(axis = 2)\n",
    "    contrast_att = contrastive_tensor.sum(axis = 2)\n",
    "    baseline_att = torch.flatten(baseline_att[~torch.any(baseline_att.isnan(),dim=1)]).numpy()\n",
    "    contrast_att = torch.flatten(contrast_att[~torch.any(contrast_att.isnan(),dim=1)]).numpy()\n",
    "\n",
    "\n",
    "#     if filename == 'determiner_noun_agreement_1':\n",
    "#       targets = [False] * (sent_len - 1)+[True]\n",
    "#     else:\n",
    "#       targets = [True] + [False] * (sent_len - 1)\n",
    "\n",
    "#     baseline_att = baseline_att[:len(targets)]\n",
    "#     contrast_att = contrast_att[:len(targets)]\n",
    "    targets = get_target(sentence)\n",
    "\n",
    "    rank_baseline = reciprocal_rank(baseline_att, targets)\n",
    "    rank_contrastive = reciprocal_rank(contrast_att, targets)\n",
    "\n",
    "\n",
    "    baseline_ranks.append(rank_baseline)\n",
    "    contrastive_ranks.append(rank_contrastive)\n",
    "    dist.append(len(targets))\n",
    "\n",
    "\n",
    "  full_baselines[explanation] = baseline_ranks\n",
    "  full_contrastive[explanation] = contrastive_ranks\n",
    "\n",
    "  AVG_dist = average(dist)\n",
    "  MRR_baseline = average(baseline_ranks)\n",
    "  MRR_contrastive = average(contrastive_ranks)\n",
    "\n",
    "\n",
    "  Results['Method'].append(explanation)\n",
    "  Results['Method'].append(explanation)\n",
    "\n",
    "  Results['class'].append('baseline')\n",
    "  Results['class'].append('contrastive')\n",
    "\n",
    "  Results['MRR'].append(MRR_baseline)\n",
    "  Results['MRR'].append(MRR_contrastive)\n",
    "\n",
    "  Results['Dist'].append(AVG_dist)\n",
    "  Results['Dist'].append(AVG_dist)\n",
    "\n",
    "  print(Results)\n",
    "dataframe_results = pd.DataFrame(data=Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GCvBYwoCx4KX"
   },
   "outputs": [],
   "source": [
    "full_baselines['lime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmqCozwreZrJ"
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "cEKpbSlwoqE9",
    "outputId": "cbcaf7a2-6961-4dd4-f131-a56a3ac267d5"
   },
   "outputs": [],
   "source": [
    "#@title #**Results:** npi_present_1 reversal results.\n",
    "results_npi_1 = {'Method': ['input_x_grad','input_x_grad', 'input_x_grad','input_x_grad', 'input_x_grad'],'class': ['baseline','baseline_Paper','tgt-foil','foil-tgt','tgt-foil_Paper'], 'MRR':[0.4699,0.510,0.4948,0.738683333,0.787]}\n",
    "df_res = pd.DataFrame(data=results_npi_1)\n",
    "# Assuming 'class' is the column containing class information\n",
    "g = sns.catplot(kind='bar', data=df_res, x='class', y='MRR', col='Method', hue='class')\n",
    "# Customize the plot as needed\n",
    "g.set_axis_labels('Class', 'MRR')\n",
    "g.set_titles(col_template='{col_name}')\n",
    "g.despine(left=True)\n",
    "\n",
    "# Add values on top of the bars\n",
    "for ax in g.axes.flat:\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_x() + p.get_width() / 2., p.get_height(), f'{p.get_height():.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "WUdcG5r36q8K",
    "outputId": "1718f838-415f-45c9-c39b-2e54d68c8ee2"
   },
   "outputs": [],
   "source": [
    "#@title #**Results:** npi_present_1 results.\n",
    "\n",
    "results_npi_1 = {'Method': ['input_x_grad', 'integrated_grads', 'lime', 'deeplift', 'gradient_shap', 'discretized_integrated_gradients','input_x_grad', 'integrated_grads', 'lime', 'deeplift', 'gradient_shap', 'discretized_integrated_gradients'],'class': ['baseline','baseline','baseline','baseline','baseline','baseline', 'contrastive','contrastive','contrastive','contrastive','contrastive','contrastive'], 'MRR':[0.4699,0.5841333333, 0.6716833333,0.45684999999 ,0.6275928, 0.54976666666 ,0.738683333,0.69993571, 0.5014499999999973,0.748433333,0.5938833,  0.6834761904]}\n",
    "df_res = pd.DataFrame(data=results_npi_1)\n",
    "# Assuming 'class' is the column containing class information\n",
    "g = sns.catplot(kind='bar', data=df_res, x='class', y='MRR', col='Method', hue='class')\n",
    "\n",
    "# Customize the plot as needed\n",
    "g.set_axis_labels('Class', 'MRR')\n",
    "g.set_titles(col_template='{col_name}')\n",
    "g.despine(left=True)\n",
    "\n",
    "# Add values on top of the bars\n",
    "for ax in g.axes.flat:\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_x() + p.get_width() / 2., p.get_height(), f'{p.get_height():.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "agR9MZ_360OF",
    "outputId": "9b7ca324-65ea-4da1-e5a5-61ae90677901"
   },
   "outputs": [],
   "source": [
    "#@title #**Results:** npi_present_2 results.\n",
    "\n",
    "results_npi_2 = {'Method': ['input_x_gradient', 'input_x_gradient', 'integrated_gradients', 'integrated_gradients', 'lime', 'lime', 'deeplift', 'deeplift', 'gradient_shap', 'gradient_shap', 'discretized_integrated_gradients', 'discretized_integrated_gradients'], 'class': ['baseline', 'contrastive', 'baseline', 'contrastive', 'baseline', 'contrastive', 'baseline', 'contrastive', 'baseline', 'contrastive', 'baseline', 'contrastive'], 'MRR': [0.5579499999999994, 0.6310166666666669, 0.6647666666666667, 0.6632000000000005, 0.7978833333333338, 0.6919000000000005, 0.5639999999999991, 0.6976000000000007, 0.6956000000000004, 0.678716666666667,0.6370833333333334, 0.6774000000000001]}\n",
    "df_res = pd.DataFrame(data=results_npi_2)\n",
    "# Assuming 'class' is the column containing class information\n",
    "g = sns.catplot(kind='bar', data=df_res, x='class', y='MRR', col='Method', hue='class')\n",
    "\n",
    "# Customize the plot as needed\n",
    "g.set_axis_labels('Class', 'MRR')\n",
    "g.set_titles(col_template='{col_name}')\n",
    "g.despine(left=True)\n",
    "\n",
    "# Add values on top of the bars\n",
    "for ax in g.axes.flat:\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_x() + p.get_width() / 2., p.get_height(), f'{p.get_height():.3f}', ha='center', va='bottom')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "HE9-tHvP68wJ",
    "outputId": "e69dc526-d2df-4fa2-b02b-584efd8db2eb"
   },
   "outputs": [],
   "source": [
    "#@title #**Results:** determiner_noun_agreement_1 results.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "results_determiner_noun = {'Method': ['input_x_grad', 'integrated_grads', 'lime', 'deeplift', 'gradient_shap', 'input_x_grad', 'integrated_grads', 'lime', 'deeplift', 'gradient_shap', 'discretized_integrated_gradients', 'discretized_integrated_gradients'],'class': ['baseline','baseline','baseline','baseline','baseline', 'contrastive','contrastive','contrastive','contrastive','contrastive', 'baseline', 'contrastive'], 'MRR':[0.9082428571428581,0.8196607142857156,0.31504126984126846,0.8419928571428584,0.5638011904761897,0.5770000000000003,0.30320277777777643,0.8205642857142863,0.5633964285714284,0.5110353174603166,0.6711214285714291,0.3070515873015864]}\n",
    "df_res = pd.DataFrame(data=results_determiner_noun)\n",
    "# Assuming 'class' is the column containing class information\n",
    "g = sns.catplot(kind='bar', data=df_res, x='class', y='MRR', col='Method', hue='class')\n",
    "\n",
    "# Customize the plot as needed\n",
    "g.set_axis_labels('Class', 'MRR')\n",
    "g.set_titles(col_template='{col_name}')\n",
    "g.despine(left=True)\n",
    "\n",
    "# Add values on top of the bars\n",
    "for ax in g.axes.flat:\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_x() + p.get_width() / 2., p.get_height(), f'{p.get_height():.3f}', ha='center', va='bottom')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQgE3NG7x4KY",
    "outputId": "754d0b6f-b922-4d5c-b784-0ee39eb070b8"
   },
   "outputs": [],
   "source": [
    "#@title #**Results:** determiner_noun_agreement_1 results.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "results_npi_1 = {'Method': ['input_x_grad', 'integrated_grads', 'lime', 'deeplift', 'gradient_shap', 'discretized_integrated_gradients','input_x_grad', 'integrated_grads', 'lime', 'deeplift', 'gradient_shap', 'discretized_integrated_gradients','input_x_grad', 'integrated_grads', 'lime', 'deeplift', 'gradient_shap', 'discretized_integrated_gradients'],'class': ['baseline','baseline','baseline','baseline','baseline','baseline','tgt-foil','tgt-foil','tgt-foil','tgt-foil','tgt-foil','tgt-foil', 'foil-tgt','foil-tgt','foil-tgt','foil-tgt','foil-tgt','foil-tgt'], 'MRR':[0.4699,0.5841333333, 0.6716833333,0.45684999999 ,0.6275928, 0.54976666666 ,0.4948, 0.49498333,0.6947166666666674,0.498061904, 0.597342857,0.50434999,0.738683333,0.69993571, 0.5014499999999973,0.748433333,0.5938833,  0.6834761904]}\n",
    "df_res = pd.DataFrame(data=results_npi_1)\n",
    "# Assuming 'class' is the column containing class information\n",
    "g = sns.catplot(kind='bar', data=df_res, x='class', y='MRR', col='Method', hue='class')\n",
    "\n",
    "# Customize the plot as needed\n",
    "g.set_axis_labels('Class', 'MRR')\n",
    "g.set_titles(col_template='{col_name}')\n",
    "g.despine(left=True)\n",
    "\n",
    "# Add values on top of the bars\n",
    "for ax in g.axes.flat:\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_x() + p.get_width() / 2., p.get_height(), f'{p.get_height():.3f}', ha='center', va='bottom')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aORzjpKpx4KY",
    "outputId": "6a46f1d0-86de-42dd-ec27-3e4540573263"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "results_npi_1 = {'Method': ['lime_true', 'lime_sub', 'lime_true','lime_sub', 'lime_true','lime_sub'],'class': ['baseline','baseline','tgt-foil','tgt-foil', 'foil-tgt','foil-tgt'], 'MRR':[0.672,0.672,0.672,0.695,0.579,0.501]}\n",
    "df_res = pd.DataFrame(data=results_npi_1)\n",
    "# Assuming 'class' is the column containing class information\n",
    "g = sns.catplot(kind='bar', data=df_res, x='class', y='MRR', col='Method', hue='class')\n",
    "\n",
    "# Customize the plot as needed\n",
    "g.set_axis_labels('Class', 'MRR')\n",
    "g.set_titles(col_template='{col_name}')\n",
    "g.despine(left=True)\n",
    "\n",
    "# Add values on top of the bars\n",
    "for ax in g.axes.flat:\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_x() + p.get_width() / 2., p.get_height(), f'{p.get_height():.3f}', ha='center', va='bottom')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "29TYA01Hx4KY",
    "outputId": "9497b799-8ca0-448b-be2f-88db9dafd9e4"
   },
   "outputs": [],
   "source": [
    "#@title #**Results:** determiner_noun_agreement_1 results.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "results_npi_1 = {'Method': ['input_x_grad', 'integrated_grads', 'lime', 'deeplift', 'gradient_shap', 'discretized_integrated_gradients','input_x_grad', 'integrated_grads', 'lime', 'deeplift', 'gradient_shap', 'discretized_integrated_gradients','input_x_grad', 'integrated_grads', 'lime', 'deeplift', 'gradient_shap', 'discretized_integrated_gradients'],'class': ['baseline','baseline','baseline','baseline','baseline','baseline','tgt-foil','tgt-foil','tgt-foil','tgt-foil','tgt-foil','tgt-foil', 'foil-tgt','foil-tgt','foil-tgt','foil-tgt','foil-tgt','foil-tgt'], 'MRR':[0.4699,0.5841333333, 0.6716833333,0.45684999999 ,0.6275928, 0.54976666666 ,0.4948, 0.49498333,0.67236904,0.498061904, 0.597342857,0.50434999,0.738683333,0.69993571, 0.5787190476,0.748433333,0.5938833,  0.6834761904]}\n",
    "df_res = pd.DataFrame(data=results_npi_1)\n",
    "# Assuming 'class' is the column containing class information\n",
    "g = sns.catplot(kind='bar', data=df_res, x='class', y='MRR', col='Method', hue='class')\n",
    "\n",
    "# Customize the plot as needed\n",
    "g.set_axis_labels('Class', 'MRR')\n",
    "g.set_titles(col_template='{col_name}')\n",
    "g.despine(left=True)\n",
    "\n",
    "# Add values on top of the bars\n",
    "for ax in g.axes.flat:\n",
    "    for p in ax.patches:\n",
    "        ax.text(p.get_x() + p.get_width() / 2., p.get_height(), f'{p.get_height():.3f}', ha='center', va='bottom')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gThIn-lPdll0"
   },
   "source": [
    "# Old Code from here down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "lZ_CHAtCo_ou"
   },
   "outputs": [],
   "source": [
    "#@title #**Loop through blimp NPI and give MRR**\n",
    "import torch\n",
    "explanation = \"deeplift\" #@param [\"input_x_gradient\", \"integrated_gradients\", \"occlusion\", \"lime\", \"deeplift\", \"gradient_shap\", \"discretized_integrated_gradients\"]\n",
    "aggregator = \"sum\" #@param [\"sum\", \"mean\", \"vnorm\", \"max\", \"min\", \"prod\", \"absmax\", \"default\"]\n",
    "attributed_fn = \"logit\" #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "rev = \"False\" #@param ['True', 'False']\n",
    "gc.collect()\n",
    "model_inseq = inseq.load_model(\"gpt2\", explanation)\n",
    "\n",
    "baseline_ranks = []\n",
    "contrastive_ranks = []\n",
    "dist = []\n",
    "\n",
    "for index, row in dataframe.iterrows():\n",
    "  sentence = row[\"one_prefix_prefix\"]\n",
    "  target = row[\"one_prefix_word_good\"]\n",
    "  foil = row[\"one_prefix_word_bad\"]\n",
    "\n",
    "\n",
    "  # encoded_target = tokenizer(' '+ target)['input_ids'][0]\n",
    "  # target = tokenizer.decode(encoded_target)\n",
    "\n",
    "  # encoded_foil = tokenizer(' '+ foil)['input_ids'][0]\n",
    "  # foil = tokenizer.decode(encoded_foil)\n",
    "\n",
    "\n",
    "  baseline = model_inseq.attribute(\n",
    "      sentence,\n",
    "      sentence + \" \" + target,\n",
    "      attributed_fn=attributed_fn,\n",
    "  )\n",
    "\n",
    "\n",
    "  contrast = model_inseq.attribute(\n",
    "      sentence,\n",
    "      sentence + \" \" + foil,\n",
    "      attributed_fn=attributed_fn,\n",
    "  )\n",
    "\n",
    "  clear_output()\n",
    "  print(f'target = {target}, foil = {foil}, sentence = {sentence}')\n",
    "  sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "\n",
    "\n",
    "  base_tensor = baseline[0].target_attributions\n",
    "  contrastive_tensor = contrast[0].target_attributions\n",
    "\n",
    "  print(base_tensor.size())\n",
    "  print(contrastive_tensor.size())\n",
    "\n",
    "\n",
    "  # contrastive_feature = base_tensor-contrastive_tensor\n",
    "  # contrastive = copy.deepcopy(baseline)\n",
    "  # contrastive[0].target_attributions = contrastive_feature\n",
    "  baseline_att = base_tensor.sum(axis = 2)\n",
    "  contrast_att = contrastive_tensor.sum(axis = 2)\n",
    "  baseline_att = torch.flatten(baseline_att[~torch.any(baseline_att.isnan(),dim=1)]).numpy()\n",
    "  contrast_att = torch.flatten(contrast_att[~torch.any(contrast_att.isnan(),dim=1)]).numpy()\n",
    "\n",
    "\n",
    "  if filename == 'determiner_noun_agreement_1':\n",
    "    targets = [False] * (sent_len - 1)+[True]\n",
    "  else:\n",
    "    targets = [True] + [False] * (sent_len - 1)\n",
    "  baseline_att = baseline_att[:len(targets)]\n",
    "  contrast_att = contrast_att[:len(targets)]\n",
    "\n",
    "  if rev == 'True':\n",
    "    contrastive_attributions = contrast_att- baseline_att\n",
    "  if rev == 'False':\n",
    "    contrastive_attributions = baseline_att-contrast_att\n",
    "\n",
    "  rank_baseline = reciprocal_rank(baseline_att, targets)\n",
    "  rank_contrastive = reciprocal_rank(contrastive_attributions, targets)\n",
    "\n",
    "  assert len(targets) == len(baseline_att), f'Target/Baseline mismatch \\n targets = {targets},\\n baseline_att = {baseline_att}'\n",
    "  assert len(targets) == len(contrastive_attributions), f'Target/Contrast mismatch {targets}, {contrast_att}'\n",
    "  assert len(contrastive_attributions) == len(baseline_att), f'Baseline/Contrast mismatch {baseline_att}, {contrast_att}'\n",
    "\n",
    "  baseline_ranks.append(rank_baseline)\n",
    "  contrastive_ranks.append(rank_contrastive)\n",
    "  dist.append(sent_len)\n",
    "\n",
    "\n",
    "AVG_dist = average(dist)\n",
    "MRR_baseline = average(baseline_ranks)\n",
    "MRR_contrastive = average(contrastive_ranks)\n",
    "\n",
    "print(f'Average Distance is   {AVG_dist}')\n",
    "print(f'Baseline MRR is       {MRR_baseline}')\n",
    "print(f'Contrastive MRR is    {MRR_contrastive}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGKxnyQv-nSh"
   },
   "source": [
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAkIAAAAjCAYAAAB4kGXWAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAB4dSURBVHhe7Z0HWFTH9sB/LsUC0kRBEFCJJWgU7MaoLxpL1KhR0BhFY4slmqemWzCxpGg0tmd82LBgw941kSiiYAtKUZ9deXRpCsouu3f/d4tSRASTl7+R+X3f/XZn5t6Be+bMuWfOnZ0pp5VBIBAI/uY8ePAAe3t7/adAIBCUFIXx889DnU220vhdIPg7Ixk//wB/QhV/LZo0LgUHsdo/gL1RaWjSLxJ9R2MsFAgE+Xnu/q1RoRLdqlRoVCqeKjL1fZJSs4wJI6VonD/ZEVJx7BNPXAduIMOY89KhSSUicAp9mn7AhmwRTHsZUV5az7jubWn2qjPOXr6siFEZSwqjITUikCl9mvLBhvxRiCwiA6bw5Zx/s2zuJIZ+5M+F+8aiFxgp6Re+mzifs5ZtGTCsF66RC/DtOZWDT7t9wTORko4wa/hI/BYv5YcJ45l38mmWMb8uZZNnWSSSjsxi+Eg/Fi/9gQnj5/G4CimJI7OGM9JvMUt/mMD4eSdfXrv7V5Hfvj81sKjk0vrx9GjbjFednfHyXU60fvCv4cayfjSsV5e6dR8d9Xh98lH9VY/R3GRl38YM35VjzChrFKPTT0FzcyV9Gw+noMgk0s4H4jdqFF8t2kVMusFNKmy/lxsap3h0r8b+TNRpN7RXE3KMqb8JaaHaA6FpxkTx3L8Vo43YOExb06KXdk2WZMwVvDTkRmtXzlyljc6Wv2vitRv6O2trjDigLVKj79/SxkRs1A5zq6TttVZ3gYHsoxO0Hk2maM/k6lI52tBPG2jdh+/Wpr3Q6nJXGzSkk3ZyeL47zT2r9fP5UntCaUy/4GRnZ2srVqxoTL0AaJK0mwfU1nZceFOr0SXvLNV2dffRBsbrUoXIr0trsrSPVEWTtFn7vntH7cIbal1Ke2dpV627T6A2XqPRJm0eoK3dcaH2pqFy7dKu7lqfwHj93xI8H4/su1ulXtp8XboAudErtTNXRWsNJmKD9r0aLtoR+x9qpdzz2p8mfK3deTpKGxMTIx+R2o3Dm2kHbskwXKgnV3t51WhtSxd77fvbHhrzyhY6nR5QW9Zpg+Lm02lD+RPkXtauGt1S62L/vjZPZLnaaxs+0Ho1HakNupHfZhWy3+/V0LqM2K99+AzbW2xESJWVhW4wmJOaSHqBUaGK7Gw5Q8omJSkTtTFXh4ltLVysNE8PYeVDlZ0t1ySRnZJEZv5K5NwHD+T6VRmkZz+Kb2nISoontZBzp8lKIi45+4komC4/vtDJRd6P6jprPhzCj2fvlShUaenmQcM6Tlj9+S8VBS8C5dzwmTiUBpXk74qqNKjvSg2X6pgYSgti6YZHwzpUL6AMKiJ27+e/bvWpb6pLl6dp+5Y83LGWA5kvcAQx5xQHj6qxdzQzZsiUs8fjnY54mhvTglIhJW5jxX472nd00YfeFU4daV/tECuCYp+wV0XrkkTitpXst21PBxedBipw6tieaodWEHQ7nm0r9mPXviMuhsrp2L4ah1YEEfvc72sEBvtevVj7Xs7Nh4lDG2AwEQ2o51oDl+omlJNtx5Cvp9GreUM8PDzweOUhkVfq0OMta8OFMsqoVWzIfYeebkValDKATqdXsN+uPR0Nipun00UqrpKoVRvIfacn+UWmjlnAsHGn6bBgAd61yhtzZQrb73pG+13OUPw0im7u7Cvs+uwf1Gw5nNnTP2bU4E5yJx3JzhQ1aedWMbp1LdoMn8ZH7/WhR4ua1Owyh1NZ8iPg9m/8OLARNfusJrmYziilnWPV6NbUajOcaR+9R58eLahZswtzTt0j9dxKxrZxp/3Hc/mkmye1eizi+o3dzJ+xkHXbVzOujReDAi7JzpdEyv6pfLQgnOu/r2aEzwzO6JwbzW12z5/BwnXbWT2uDV6DAricqbuf9rg9cT8S92OOcTDyv8QeX8WSref4G7zBEPwvMbGksoXha3Z0AAsu92DRp43R+zQlQkvOwxxyMzO4Z+wDCnt7rB/e5mb8CzwpwKwmrzidYsY7Pnw6dy2HopJQmrjR3/ctvcEXlB7VudNEqqrj4mq04CbOuDhKRJ87rx+QPRsV585Eoqpeg7wqXHCUojl39hSnI1VUd3E1OukmOLs4IkWf43zJKhc8JyaWlTGYiGyiAxZyuftCPvGUBxAmNtha5z1SVed3ctypO51tjRkPzuC/tTwDh9Qj33CjjCHr9GmdTrs8qdNFKO6DM/5sLT+QIfXySyyHY0v/RbhNPcwPf85A7wGMnbOfW7rLC9nvhZe7s/ATz2fKu2hHyKIuXdq4oc2uTLOJC1mzw5/BZrvYEqLGrmkfmttl8NCxG3O3HCLstD/tY75lasAtzN3a0cfLiqzc4ke+Crum9GluR8ZDR7rN3cKhsNP4t4/h26lrqdLUm5b26SRpGzHt8EVubn2XsClLSG7zNh07evNxT0u2T53PrzkqwoLk0Y99Y9p0HcP0Ua2pqJBI2vgFi5Pb0K1jR7w/7onFtqnMC3M13E9WZZpPWqS/H1/TnfL9qKjcuAuvO5vh3P5DJvRvSmXj/ygoy0gkn1rJN9N/5uDOmQz6dD9pxpJnU54mXTtif2YTq6N0kwwkMuISySpnhbXNM4Yl/5+YeDBp03a+aJLOwXmj6eb5Ci0mHiS1wIBGSeyp3WzeuIH1a9azNzKRi0dD0c+lllI4t3MNq1cHsGaTMa+Mo05P5155SywfW2ETLCtXJEvOzzXmFI+a9PR7lLe0zDPkOkNfMYv01Luk3yuPZV7l+gd0xax00ktWueCPICVzauU3TP/5ADtnDuKzfan55nXpUHF+5zEcu3fFTp++T+jPe7EfOoi6JR9VvYQUo9OFFfd+KD/vtWfooLoFB6Lqa5w4lYBDq36MmbqE1T8NQBPQn57Tw4wn5NnvAzr7/dk+Up8RjH96ANDMDNNKNthVlL+bWFPZMofsbJ11M8fcTIFVFXvZ5MsVOHTH+01zYn6PllPlMDMvWRzd3NwMhVUV7A2V0N37TcxjfpcTZpiZmmFfwxVLRSVsLSL4JTQLZUIMkZFRxHn8k7WLfKkj/x+t3m3Ptc9b88aH/sS91oGGprJzdDiUbGUi0ZGRRMV5MGHdInzr6KoteD9Wj+9HICiMgmothzNn2xl+3/Qe6sB/s6cUs1Bte8xl87cNCP98ECM+m8nKw1e4596CFlWf3t1eBMxdu/BlQDDR8fFcWNWL7FXL2HfPWJgVwbIxI1l6w52u/d9n0BBv3E99RP9lt7HSjewUVfFqfp9Niy9Rr88bj0d7ZRlTa2ssc3PIeWxmJHIeKqloZVXCiIAp1taW5Obk5E01kHJ4qKyIlY0d1pa55ORVLhc9RFnRCquSVS74Iyiq0XL4HLad+Z1NAzRs8N9DRv6Hreo8O4860r2rIRyUfmQ+2yr2oI1JPLH/TeK+SuJhehzxqWVtqYdidLqA4qZzZP42KvZog0l8LP9Nuo9Kekh6XDypWZlk3lfwSqt2OMvuhrlLdz4f2phr27car81vv2UnaYO/bL+fEZwxfv4B5FGOhQU2dga/93kxsbTAQu7cT6ATUvZDrBr0oq+3N966o3cTqqnBvsdSjh/yo2HkN3Ru/QGb4tSyocnmoVUDej8617s3TeSTxWtzQelR4Pj2+3SqpiQ7pxQapKhC63Gy83RoOytme6O4/F+ajxxCE7MXNCKUuQP/wLi8PqKwoWH/vrzuYImFzjZJCWwZO4bj7b5n9oAGGKL/FajXrTM+7dpgpUvKZJ84SUKLDniJOUV6zBp54qFIJTnFKFkpneS7EvUbNSqhI2RGo8YeKFJTyKsimbtSfRp5eeHpoSA1OcXYbhLpyXeR6jeikXCE/joUjrw9oBPVlA/IbyJ0r8V+c+jO21V0nUVN3KVLnF47nn4+Pvj0H8/6/2QQOlceUMw7YbigzCDrtKdOp5Of1On8iquO49Kl06wd3w8fWWb9x6/nPxmhzH1/EPNOOeDmbMK9tFSj7ptQ3aU65urCoVCd/R6gt98PnmG/n+4IFXCgtOiXXcy39qJWkgynaG7x+2VrusnOiSFfzpXPK3D509BK6E7XTYS+9ftlrLv11mfLBcZPmfJNaNnoBiumr+DiQzktpREyfwEH0h+wZ/k6clqOYXnoMaa7HOXA2XI0adWI6yv8WHFR9zs7ibSQ+Sw4kF6gSl0i735MMTWFXKWyZP+zjpLen+BviSTr9iOkuzdIa9CdzvpoThbXToRypcBEMqMuFYX84Av5ejSBjjNYPLpeKeYZ/bUow4M5cDM9zxGSSf8tmJTuQ+lsIdukqGXMvfAPPu7rVMBgKJw/4IsRNY15Ss6ExFC/bUt9pFggm2fX3ni3uknYyUxDxr1QTtxoSX/vWrLpLokumeDauy+tboURZpxofy/0BDda9sf7lVryYK8VN8NOYqj9HqEnbtCyvze1RDTuj1GUfc+6xonQK8Y5pPJz63Fnkbh7I40G3TtR9bHcVZzfEUy1bt0wBIFNaThuEyfCwwnXHSe3M97Ljk7fHiP42076K8oOOp32ptXNMPK6hVGndYr7SM6mDRm36YRBXvJxcvt4vOw68e2xYL7tUovuvZoTKz/34/TtoCEpLgXLlm319RVlvzvlNU6RFO0I5dziaHAkaUkXOBJ2i9gzewi7ncPV0INc0a9ZJBEXvIhZPy1j0eQfuNVvBdPfqMCDW6FsC7mG8noI207FF/g1WVFIccEsmvUTyxZN5odb/WRn53VSzgXx66UH3D6+nf3RssdnUpdRP0zDM3ISXk5uNGg9hIP1huLtoiAn/N9MXbyH0NBTJLuPYGh7C+qOmoNf4wtM9KyOW4PWDDlYn2E9NITo7ic5735O3lYa7ueBLU1avkKM/zg+nXeAG8/4p5VxZ9m19Rh3cq4SEnSUy2n5Hx+Cvz2ZW/F1daXN8NksX7uapYG5DFs8lld0/ShzD1/16MHn21MN5yrjOLtrK8fuyLp0LIijl40ziaQsboYGMnPUGNbb+rFn3VDqv7CjdDXRpxJQJKxj5vJ9hF84y5GAmXwT2oI5szrq58ypLl4kwaMprxkjPVLiaXasmstXn/3I5ogkgwOlvsyxs1V5/Y1H8SEBJrUYuWAG1lsns2zfPvynbKaS3yJG15aVqThdCsnTJZNaI/npGxu2Tvk3+/b5M2VzJfwWjaa2iQm1Ri5ghvVWJi/bxz7/KWyu5Mei0bXlR43geXls35VXOZbPvmfu+YoePT5H11yZWwfj5taG4bOXs3b1UgJzh7JobJ28gY7qPDuC7enWvVoxkYayi06nF8ywZuvkZYV0uqCcn44J7qOXMMd1FxP91rNv98/MO9+Sf33fR9c4T9jvoYvGUucZo9Dn2GLjAet6O7Co6Ql++dAeydYJu+cIhT9Y1xuHRU058cuH2Eu2OD2rEukByXGZVKxencrGm9JoNJRTphF7FxxqVKXCY62TeJAcR2bF6lR/dHJxyHWnJKuwdbR5YUftgr8OVdoNLstDDUf32lSrVNCU5WTKwxhrayoY00UhpcQQdsOM+l51qfLCvyaSSIlPwsrJgdzYKH6/eJeK9ZrRpKb14weqOmI67aZUI2jvRzgbxaE8Mo4Wy1pxNGgQulkQUuwS3u6byLcnZ9H0/6kTvbBbbMj2JfFaLLkO7rhY5wmnJLr0COlBItdic3FwdyFfFTKyrUu8RmyuA+4u1sJ+/c/IwdBcutZSkXbjMnGSI+61q1HIRMhNkkVyogprJzsRHS2GonU6v5yfjTLlOjezbKldy45HprY4+/00nsMRymZtb0cWNQkj3K/h0zue8iizB/7E6SJ+wWDWdDxLay7BfVETwsL9aPjC9F4lR2cP5Kei/2nGB/jxlqUxLRCUGTIJX/gF/rGv0KFTC5xyYrl8di8XXH7g5w9dUV//jfVLvmZ6RAv+tWQqPRvmrZvyVyL2GhMIBM9DKR0hiaTTq5jy0dccdxrBrGmj6dvMsdThPynpNKumfMTXx50YMWsao/s2w7G0lQgEgr8UKSeFm9fvYuZUmxq25V+4sL9whAQCwfMgdp8XCAQvBcIREggEz4OIwwgEgpeCcuXKUb9+fWNKIBAISoZwhAQCwUuBLrh9+fJlY0ogEAhKhnCEBAJBHpo0LgUHsdo/gL1RaWjSLxL9aL8MKZWYqDt5K8IKSoiGjNg7pJVoDzANaQlJ6FZBexKJtOvniLyjX8OkIFIa189FUlSRoJRoMoi9k0bxzaVBlfNA/xpWf+Tk6DftltRKch7lPS5T5eszpdGFl5xnyVlSo8wvY/1hkLMejaqArHNkOT9GncHt/9wktYRyFo6QQCDQIyX9wncT53PWsi0DhvXCNXIBvj2nclAlkRIaxJ6LMezaeYrbIZs4cF24QyVBE7uTCW92we/wYaZ1eZMvf0mW3Zki0KQSue17RnSoi/s7P3OliP0acy78SN9mrem3OKrQwyOHCz/2pVnrfiyOEk/Y50dD7M4JvNnFj8OHp9HlzS/55Sm7h6vP+NHU2gILC8Nhad2B+Vcz2T7YWb/TwqN83WHd+CvC5WYpsS689JRMztnbB+NUSJYW1o35SidM1JyZ1gSrx2WWWHf4Sc7XcGv7BNo0Gc6Oq8F82rIh7/3rDM/aIUk4QgKBQCaV7V/MJWvgNHxbOFLB1JZG/XtRp3o9Xnc1o0pDD5Q7VnIkOJB/X62Jl4tYtu+ZSMlsmjSSpfGN6Oc7mEHNEpj//mjWxRcy+lIGF/buJSx0D0FHb5Bd1M9XMo7x/UdzCSliz6SMY98xdk5Iwb2uBKVGSt7EpJFLiW/UD9/Bg2iWMJ/3R6+jcHPpHrbXQm5Qtdu7vPuu4eg7bjz9al7jwpVyOHk0xtPTUz4a4mJlRp3ePjQ3LaEulAFKJmc1ly/8h3LOHjTWy9KThi5WmNXpjU9zc7kJrhFyoyrdjfJ/992+jBvfDylhHRNGLOasfXv6vD0I3zcesG2iLzNDHha7G4RwhAQCAeSc4uBRNfaO+ZbALmePxzsd8TSXuBu2l7M27enQtRON4g9w5FlLsAuQ4ray5kAqWNlhZ2JClSq2sr95gIAtdwpGAhQ2NO41hKE+rale1JpqUiK75h3Atp3HE+u2SYm7mHfAjvYNXpjF2P6mSMRtXYOhuewwMamCobkC2HKnsOMaR/CNKgz7bAYLVgexfft2guYNoHbOTSwG/cq1mPNEREQQcfRr2lV+ld7ezTAtqS689JRUzlnctPDlyLUYzutkGXGUr9tV5tXe3jST/SDdrhTX7Yfz2YwFrA7aLrdBEPMG1EIVfoTQTLmecgpM5N7iUM0eRe51dm8/rdvB5qkIR0ggEIBZTV5xOsWMd3z4dO5aDkUloTRxo7/vW1SSzUS1t7/g+zGv417DC+9p3zCwvnjwPgvVuXAiHsrW19RUNsnlMDeXnUytiqhzEUXPiyhXTj6rMBpuBs4hvOk/6V2tUBROc5PAOeE0/WdvqglL/gdRcS48AkNzybpdzhxDc0VxLqJQa6UGc3j9z/i2eY2a1Zxp5ruAk7qtOGy8+XJCY+MKxxIpezbwS9Ve9PMyLb0uvLSUVM42eH85gcbG5aKllD1s+KUqvfp56QcDqcGHWL/Ulzav1aSaczN8F4aRrvOjzMz05drMNNIk3d59Ou9HQ1J8gvz5dET3EQgEYOLBpE3b+aJJOgfnjaab5yu0mHiQ1PyDNNP6vDfwdbFtQAlRZ2aSpbPDBZDIkvOLWLu+SDTXVrPwSmc+ecehkJOk4drqBVzp/Ck9HZ50nwSlRU1mZtaTQQMpS84v2FrqZC0unbrQ9jVnLKVkzq3/hL5jNpGYf9qclMjODUdx6e2j3znhz9CFl4OSyzkPicSdGzjq0hsf/TYUapK1LnTu2pbXnC2Rks+xflIfRm9OosI/fBlQzxz1pYNsi0gmIUm3mbQC2ypVDFU9BeEICQQCPeauXfgyIJjo+HgurOpF9qpl7LtnLBSUGlNrayyf8FEUWMj5+V5AFkMqQd9uIr3CZdYvXkjAiTjZqGvJPL+TfSc3MntjBhUur2PRwgBO6CZYaDM5v3MfF8tWiOFPwhRra8snI3IKCzm/YGuZNhjK4q37CYm8Q+yFTUxoZUPK4d2E6MIcRjS3g9gY5k5vb8PrzD+uCy8LJZfzYzS3CdoYhntvbzx0wpTraDB0CVv3hxB5J5YLmybQ0jqFw7tCwPJN5v56mJ8nNSV+5WS+3XULtaIKb3RoRhHh1scIR0ggKOtk7sA/UPeQNaKwoWH/vrzuYIlFAdukJPbUbjZv3MD6NevZG5nIxaOh6H9dL6VwbucaVq8OYM0mY14Zx9yzCQ3NZeurVstjWC1KpeyhlDPntSae+oefOidHzi8G6T7x14+zdupEJk6cxPStV+TzNST+upBVJ+9w/fhapk6UyyZNZ+sVuSZNIr8uXM1ppfF6QSkwx7NJQwzNJctSq8TQXK/RxFPfWuTkFG4tBdYe/Zjr/zFeFc0we/zmUsPVzZs4W78P3vUNmc/ShbJD6eWsubqZTWfr08e7/uONoB+jsMaj31yW/9OTCmZ6LwlTp/aMmrmYJWNqknVXi1WbSXzR07Y4P0g4QgJBWUcZHsyBm7oQch7pvwWT0n0onS2MGVkRLBszkqU33Ona/30GDfHG/dRH9F92GyuddVJUxav5fTYtvkS9Pm/g+oTFKnsoXH0Y3KWK7GimkqrRcPduOth1ZrC3G1n7x+Jha0O9kbuRcw3k5sqPUBmNZHCQFK6M3nmHhIQE+YgjbFpz+aFpSp2xO1g1dgK7YnX58hEXxrRm8kPEtA5jd6zkvcq6iwWlQ4Grz2AMzZWKRnMXQ3MNxtsti/1jPbC1qcfI3YmcnN2F5m8M5LuDt/Xze1T3VLi+N4Q3KxgfteooNm6JpnEfb+oY+0FxulC2ukpJ5fyoV6iJ2riF6MayU/lImMqTzO7cjDcGfsehO/oW4J7SlQFDOhjKZaS0EL4ZvZDrjSYQuPETGj3jfb5whASCMo2a6FMJKBLWMXP5PsIvnOVIwEy+CW3BnFkd0T9TpQS2jB3D8XbfM3tAA6z1VqMC9bp1xqddG6x0SZnsEydJaNEBL+MExzKPwpkh/huYVCOCwIB1bD7vxIT1/nzgokCdlcG9XDX3M+6jku5z8cByZs/bwy3ZA1Jf2cFPP20kPAEq2Trg6OgoHw7YVTKMeBWVbLCuVAlbB12+fDjYYShSUMnGWm4ZwfOgcB6C/4ZJ1IgIJGDdZs47TWC9/we4KNRkZdwjV32fjPsaLCxMSPx9I1N6eNGk+zAmhzTjh+/ewsboB6nObiToalP69K2V5+QUowtljZLJWefgyKjOsiHoKk379KXWI2GaWGJhksi5jVPo7tmE7sMmE9J8Dt+9ZS07QJFsX/Alw4bNJ6VPIGdD5tHD2dBvikNsuioQlGkkUuKTsHJyIDc2it8v3qVivWY0qWn92IirL0yn9WAlS858T8sCTo4urF2e8vo8JcHjWrCs9TG2DLTRl/7V6FaXfTE3XdWQEZeI1sEZ28c2WUXqrXhwqkkV4Ti+WGgyiEvU4uBsq5/fo0eViqG5quh/FabJTiUlpyJVq1QqZUSnKF0oo5RAzk9HQ3ZqCjkVq1KlUr4WyEomQW1DdZvSdSrhCAkEgmJ5sNGHurv7cUX+rCSnpcTT7Np/jNOXVLzqPYJBLR1QqC8w/Y1PsN18mAlu/z+j3BfXERIIBC8y4tWYQCAoFvP6HrhmJhvW6ZBROLagm9tt9t9y4x2dEyTnSQnHCZda0dZZmBSBQPD3QlgtgUBQLKZek5jfJYppn//I+kMhBO8KZOXRVFp1aoe1XK66/hsB84O4WElJ3OVMw0UCgUDwN0G8GhMIBCVCyknh5vW7mDnVpoZt+RduFPXw4UNatGhBVFSUMUcgEAiejXCEBALBS4GYIyQQCJ4H8WpMIBAUiSbtEsFBq/EP2EtUmob0i9FiocS/ivyLOhWimCIjau4npZJlTAn+92hk57tU61hqVKhEXyo1T5ezRh4AFV2ivp9E6jM6g3CEBAJBISSSfvmOifPPYtl2AMN6uRK5wJeeUw+WsQ0i/zykpCPMGj4Sv8VL+WHCeOadzDCWFER5aT3je7Sl2avOOHv5sjz6kXFXcmn9eLq3bcarzs54+a4gplBjSGnnCfQbxaivFrErJt2wOKOgdGhSiQicQp+mH7ChuMCi6gyzO79K3bp15aMerSf/pt9IVIcmNYLAKX1o+sEGiqxCc5OVfRszfFeOMaOsIduXI7MYPtKPxUt/YML4eTylOxjk3Kl+Pjkf5ZHUVGdm06m+Ll8+6rVm8tF88pTSOB/ox6hRX7FoVwzpxXYG+D8TkXBnykwjNAAAAABJRU5ErkJggg==)\n",
    "\n",
    "npi_present_1:\n",
    "\n",
    "Average Distance is   3.15\n",
    "\n",
    "Baseline MRR is       0.470\n",
    "\n",
    "Contrastive MRR is    0.495\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "npi_present_2:\n",
    "\n",
    "Average Distance is   2.489\n",
    "\n",
    "Baseline MRR is       0.558\n",
    "\n",
    "Contrastive MRR is    0.769\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "............![image.png](data:image/png;base64,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)\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "determiner_noun_agreement_1\n",
    "\n",
    "Average Distance is   1 (always)\n",
    "\n",
    "Baseline MRR is       0.908\n",
    "\n",
    "Contrastive MRR is    0.394\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "npi_present_1: REVERSED\n",
    "\n",
    "Average Distance is   3.15\n",
    "\n",
    "Baseline MRR is       0.470\n",
    "\n",
    "Contrastive MRR is    0.739\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "determiner_noun_agreement_1: REVERSED\n",
    "\n",
    "Average Distance is   1 (always)\n",
    "\n",
    "Baseline MRR is       0.908\n",
    "\n",
    "Contrastive MRR is    0.577\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "TmE-J7zqJD5o"
   },
   "outputs": [],
   "source": [
    "#@title #**Plots** ?\n",
    "\n",
    "# Data for MRR-baseline\n",
    "labels_baseline = ['npi-1', 'npi-1*','npi-1-rev', 'det', 'det*',  'det-rev']\n",
    "MRR_baseline = [0.470, 0.463, 0.470,0.908, 0.983,  0.908]\n",
    "\n",
    "# Data for MRR-contrastive\n",
    "labels_contrastive = ['npi-1', 'npi-1*','npi-1-rev', 'det', 'det*',  'det-rev']\n",
    "MRR_contrastive = [0.495, 0.759, 0.739, 0.394, 0.603, 0.577]\n",
    "\n",
    "# Color palette\n",
    "colors = sns.color_palette('Dark2')\n",
    "\n",
    "# Plotting MRR-baseline and MRR-contrastive horizontally\n",
    "fig, (ax_baseline, ax_contrastive) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.4\n",
    "bar_positions = np.arange(len(labels_baseline))\n",
    "\n",
    "# Bar plots for MRR-baseline\n",
    "ax_baseline.bar(bar_positions, MRR_baseline, color=colors[0], width=bar_width, edgecolor='grey', label='MRR-baseline')\n",
    "\n",
    "# Adding labels and legend for MRR-baseline\n",
    "ax_baseline.set_xlabel('Labels', fontweight='bold', fontsize=15)\n",
    "ax_baseline.set_xticks(bar_positions)\n",
    "ax_baseline.set_xticklabels(labels_baseline)\n",
    "ax_baseline.legend()\n",
    "\n",
    "# Bar plots for MRR-contrastive\n",
    "ax_contrastive.bar(bar_positions, MRR_contrastive, color=colors[1], width=bar_width, edgecolor='grey', label='MRR-contrastive')\n",
    "\n",
    "# Adding labels and legend for MRR-contrastive\n",
    "ax_contrastive.set_xlabel('Labels', fontweight='bold', fontsize=15)\n",
    "ax_contrastive.set_xticks(bar_positions)\n",
    "ax_contrastive.set_xticklabels(labels_contrastive)\n",
    "ax_contrastive.legend()\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plots horizontally\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "BWZuQvPWv5fA"
   },
   "outputs": [],
   "source": [
    "#@title #**Inseq:** explanations with paper hyperparams\n",
    "sentence = \"Can you stop the dog from\" #@param {type:\"string\"}\n",
    "target = \"barking\" #@param {type:\"string\"}\n",
    "foil = \"walking\" #@param {type:\"string\"}\n",
    "explanation = \"input_x_gradient\" #@param [\"input_x_gradient\", \"integrated_gradients\", \"occlusion\", \"lime\", \"deeplift\", \"gradient_shap\", \"discretized_integrated_gradients\"]\n",
    "aggregator = \"sum\" #@param [\"sum\", \"mean\", \"vnorm\", \"max\", \"min\", \"prod\", \"absmax\", \"default\"]\n",
    "attributed_fn = \"logit\" #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "contrast_attributed_fn = \"contrast_logits_diff\" #@param [\"contrast_logits\", \"contrast_prob\", \"contrast_logits_diff\", \"contrast_prob_diff\"]\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "model_inseq = inseq.load_model(\"gpt2\", explanation)\n",
    "\n",
    "\n",
    "baseline = model_inseq.attribute(\n",
    "    sentence,\n",
    "    sentence + \" \" + target,\n",
    "    internal_batch_size=50,\n",
    "    attributed_fn=attributed_fn,\n",
    "    n_steps=500\n",
    ")\n",
    "\n",
    "\n",
    "contrast = model_inseq.attribute(\n",
    "    sentence,\n",
    "    sentence + \" \" + foil,\n",
    "    internal_batch_size=50,\n",
    "    attributed_fn=attributed_fn,\n",
    "    n_steps=500\n",
    ")\n",
    "\n",
    "\n",
    "contrastive_feature = baseline[0].target_attributions - contrast[0].target_attributions\n",
    "contrastive = copy.deepcopy(baseline)\n",
    "contrastive[0].target_attributions = contrastive_feature\n",
    "\n",
    "\n",
    "if explanation in [\"input_x_gradient\",\"occlusion\", \"lime\", \"discretized_integrated_gradients\"]:\n",
    "  out = model_inseq.attribute(\n",
    "      sentence,\n",
    "      sentence + \" \" + target,\n",
    "      attributed_fn= contrast_attributed_fn,\n",
    "      contrast_targets= sentence + \" \" + foil,\n",
    "      # We also visualize the corresponding step score\n",
    "      step_scores=[contrast_attributed_fn]\n",
    "  )\n",
    "\n",
    "\n",
    "clear_output()\n",
    "\n",
    "\n",
    "print(\"Baseline saliency with forced target\")\n",
    "baseline.show(aggregator = aggregator)\n",
    "print(\"Baseline saliency with forced foil\")\n",
    "contrast.show(aggregator = aggregator)\n",
    "print(\"Contrastive saliency by subtracting feature matrices\")\n",
    "contrastive.show(aggregator = aggregator)\n",
    "if explanation in [\"input_x_gradient\",\"occlusion\", \"lime\", \"discretized_integrated_gradients\"]:\n",
    "  print(\"Contrastive saliency by inseq library\")\n",
    "  out.show(aggregator = aggregator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dMUpLXrir8Vg"
   },
   "outputs": [],
   "source": [
    "#@title #**Loop through blimp NPI and give MRR** Use for disc_int_grads\n",
    "#@markdown I hate colab so much pls kill me.\n",
    "import torch\n",
    "explanations = [\"input_x_gradient\", \"integrated_gradients\", \"lime\", \"deeplift\", \"gradient_shap\"] #\"discretized_integrated_gradients\"\n",
    "attributed_fn = \"logit\" #@param [\"logit\", \"probability\", \"entropy\", \"crossentropy\", \"perplexity\", \"pcxmi\", \"kl_divergence\", \"in_context_pvi\", \"mc_dropout_prob_avg\", \"top_p_size\"]\n",
    "revs = ['True', 'False']\n",
    "Results = []\n",
    "\n",
    "\n",
    "for explanation in explanations:\n",
    "\n",
    "  gc.collect()\n",
    "  model_inseq = inseq.load_model(\"gpt2\", explanation)\n",
    "\n",
    "  for rev in revs:\n",
    "\n",
    "    baseline_ranks = []\n",
    "    contrastive_ranks = []\n",
    "    dist = []\n",
    "\n",
    "    for index, row in dataframe.iterrows():\n",
    "      sentence = row[\"one_prefix_prefix\"]\n",
    "      target = row[\"one_prefix_word_good\"]\n",
    "      foil = row[\"one_prefix_word_bad\"]\n",
    "\n",
    "      baseline = model_inseq.attribute(\n",
    "          sentence,\n",
    "          sentence + \" \" + target,\n",
    "          attributed_fn=attributed_fn,\n",
    "      )\n",
    "\n",
    "      contrast = model_inseq.attribute(\n",
    "          sentence,\n",
    "          sentence + \" \" + foil,\n",
    "          attributed_fn=attributed_fn,\n",
    "      )\n",
    "\n",
    "      clear_output()\n",
    "      print(f'target = {target}, foil = {foil}, sentence = {sentence}')\n",
    "      sent_len = len(tokenizer(sentence)['input_ids'])\n",
    "\n",
    "\n",
    "      base_tensor = baseline[0].target_attributions\n",
    "      contrastive_tensor = contrast[0].target_attributions\n",
    "\n",
    "      print(base_tensor.size())\n",
    "      print(contrastive_tensor.size())\n",
    "\n",
    "\n",
    "      baseline_att = base_tensor.sum(axis = 2)\n",
    "      contrast_att = contrastive_tensor.sum(axis = 2)\n",
    "      baseline_att = torch.flatten(baseline_att[~torch.any(baseline_att.isnan(),dim=1)]).numpy()\n",
    "      contrast_att = torch.flatten(contrast_att[~torch.any(contrast_att.isnan(),dim=1)]).numpy()\n",
    "\n",
    "\n",
    "      if filename == 'determiner_noun_agreement_1':\n",
    "        targets = [False] * (sent_len - 1)+[True]\n",
    "      else:\n",
    "        targets = [True] + [False] * (sent_len - 1)\n",
    "\n",
    "      baseline_att = baseline_att[:len(targets)]\n",
    "      contrast_att = contrast_att[:len(targets)]\n",
    "\n",
    "      if rev == 'True':\n",
    "        contrastive_attributions = contrast_att- baseline_att\n",
    "      if rev == 'False':\n",
    "        contrastive_attributions = baseline_att-contrast_att\n",
    "\n",
    "      rank_baseline = reciprocal_rank(baseline_att, targets)\n",
    "      rank_contrastive = reciprocal_rank(contrastive_attributions, targets)\n",
    "\n",
    "      assert len(targets) == len(baseline_att), f'Target/Baseline mismatch \\n targets = {targets},\\n baseline_att = {baseline_att}'\n",
    "      assert len(targets) == len(contrastive_attributions), f'Target/Contrast mismatch {targets}, {contrast_att}'\n",
    "      assert len(contrastive_attributions) == len(baseline_att), f'Baseline/Contrast mismatch {baseline_att}, {contrast_att}'\n",
    "\n",
    "      baseline_ranks.append(rank_baseline)\n",
    "      contrastive_ranks.append(rank_contrastive)\n",
    "      dist.append(sent_len)\n",
    "\n",
    "\n",
    "    AVG_dist = average(dist)\n",
    "    MRR_baseline = average(baseline_ranks)\n",
    "    MRR_contrastive = average(contrastive_ranks)\n",
    "\n",
    "    Results.append((f'Method: {explanation}', [AVG_dist,MRR_baseline,MRR_contrastive]))\n",
    "    print(Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7QAk2_n5Mz2"
   },
   "source": [
    "hallo ik ben jan"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
